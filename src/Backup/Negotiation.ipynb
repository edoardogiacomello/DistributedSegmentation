{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Automatic pdb calling has been turned OFF\n"
     ]
    }
   ],
   "source": [
    "import DeepLabModel\n",
    "import os, urllib\n",
    "from PIL import Image\n",
    "from io import BytesIO\n",
    "import numpy as np\n",
    "from skimage.io import imshow\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import gridspec\n",
    "from ipywidgets import FloatSlider, interact, fixed, HBox, VBox, Label, Button, Output, IntProgress, FloatProgress\n",
    "%pdb 0\n",
    "plt.rcParams['figure.max_open_warning'] = False\n",
    "import pandas as pd\n",
    "import IPython\n",
    "%matplotlib inline\n",
    "from skimage.measure import label"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Combining Segmentation models using Cooperative Negotiation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Agent():\n",
    "    def __init__(self, agentname, model, alpha):\n",
    "        self.agentname=agentname\n",
    "        self.model=model\n",
    "        self.task = None\n",
    "        self.optimal = None\n",
    "        self.alpha = alpha\n",
    "        \n",
    "    def new_task(self, image):\n",
    "        self.task, self.optimal = self.model.run(image)\n",
    "        print(self.optimal.shape)\n",
    "        return self.optimal, self.utility(self.optimal)\n",
    "    \n",
    "    def _dice_score(x, y):\n",
    "        x_and_y = np.count_nonzero(np.logical_and(x, y))\n",
    "        card_x = np.count_nonzero(x)\n",
    "        card_y = np.count_nonzero(y)\n",
    "        return 2*x_and_y/(card_x+card_y+1e-16)\n",
    "    \n",
    "    def utility(self, proposal):\n",
    "        # Since we are using the smooth dice loss, we have to split each label in the segmentation and sum up their scores\n",
    "        dist =lambda x,y: 1.-Agent._dice_score(x,y)\n",
    "        labels = np.unique(proposal)\n",
    "        util = np.sum([dist(proposal==l, self.optimal==l) for l in labels])\n",
    "        return util\n",
    "    \n",
    "    def propose(self, agreement):\n",
    "        negotiation_map = np.zeros_like(agreement[0]) # For keeping track on what pixels are still to negotiate\n",
    "        proposal = np.zeros_like(agreement[0]) # Initialize an empty proposal\n",
    "        for l, conf in agreement.items(): # For each \"probability map\" received in the agreement\n",
    "                proposal[conf==1] = l\n",
    "                negotiation_map[conf==1] = 1\n",
    "\n",
    "        x, y=np.where(negotiation_map!=1)\n",
    "        \n",
    "        \n",
    "        \n",
    "        for x, y in zip(x, y):\n",
    "            # For each pixel, pick among the possible labels with the relative probability\n",
    "            labels = list(agreement.keys())\n",
    "            probs = [agreement[l][x,y] for l in labels]\n",
    "            belief = self.optimal[x,y] # The agent thinks that the right label is this one\n",
    "            if np.random.random() < self.alpha[belief]:\n",
    "                proposal[x,y] = belief\n",
    "            else:\n",
    "                proposal[x,y] = np.random.choice(labels, p=probs)\n",
    "\n",
    "                \n",
    "                \n",
    "        proposal = proposal.astype(np.int)\n",
    "        utility = self.utility(proposal)   \n",
    "        return proposal, utility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Mediator():\n",
    "    def __init__(self, agents):\n",
    "        self.agents = agents\n",
    "        self.last_step=0\n",
    "        \n",
    "    def start_new_task(self, image):\n",
    "        self.task = image\n",
    "        received_proposals = [agent.new_task(self.task) for agent in self.agents]\n",
    "        self.initial_proposals = np.array([a[0] for a in received_proposals]) # Shape (agents, h, w)\n",
    "        utilities_array = np.array([a[1] for a in received_proposals]) # Shape (agents, )\n",
    "        self.initial_utilities = np.transpose(np.tile(utilities_array, [self.initial_proposals.shape[1], self.initial_proposals.shape[2], 1]), [2,0,1]) # Shape (agents, h, w)\n",
    "        self.last_proposals = self.initial_proposals\n",
    "        self.last_utilities = self.initial_utilities\n",
    "        return self.last_proposals, self.last_utilities          \n",
    "\n",
    "    def negotiation(self, timeout = 1000):\n",
    "        for i in range(self.last_step, self.last_step+timeout):\n",
    "            self.last_step = i\n",
    "            # Agreement must be built label-wise (averaging over the values could produce new labels)\n",
    "            \n",
    "            all_proposed_labels = np.unique(self.last_proposals)\n",
    "            agreements = {l:None for l in all_proposed_labels}\n",
    "            for l in all_proposed_labels:\n",
    "                prop = (self.last_proposals==l)\n",
    "                util = (self.last_utilities==l)\n",
    "                agreement_l = np.sum(prop*(1+util), axis=0)/np.sum(1+util, axis=0)\n",
    "                agreements[l] = agreement_l\n",
    "            \n",
    "            \n",
    "            # Propose the new agreement to the agents\n",
    "            received_proposals = [agent.propose(agreements) for agent in self.agents]\n",
    "            \n",
    "            \n",
    "            self.last_proposals = np.array([a[0] for a in received_proposals]) # Shape (agents, h, w)\n",
    "            utilities_array = np.array([a[1] for a in received_proposals]) # Shape (agents, )\n",
    "            self.last_utilities = np.transpose(np.tile(utilities_array, [self.last_proposals.shape[1], self.last_proposals.shape[2], 1]), [2,0,1]) # Shape (agents, h, w)\n",
    "            \n",
    "            yield agreements, self.last_proposals, self.last_utilities\n",
    "        return agreements, self.last_proposals, self.last_utilities"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading Deep Learning Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model already present at ../models/deeplabv3_pascal_train_aug_2018_01_04.tar.gz\n",
      "Loading model xception_coco_voctrainaug...\n",
      "xception_coco_voctrainaug loaded successfully!\n",
      "model already present at ../models/deeplabv3_pascal_trainval_2018_01_04.tar.gz\n",
      "Loading model xception_coco_voctrainval...\n",
      "xception_coco_voctrainval loaded successfully!\n",
      "model already present at ../models/deeplabv3_mnv2_pascal_train_aug_2018_01_29.tar.gz\n",
      "Loading model mobilenetv2_coco_voctrainaug...\n",
      "mobilenetv2_coco_voctrainaug loaded successfully!\n",
      "model already present at ../models/deeplabv3_mnv2_pascal_trainval_2018_01_29.tar.gz\n",
      "Loading model mobilenetv2_coco_voctrainval...\n",
      "mobilenetv2_coco_voctrainval loaded successfully!\n"
     ]
    }
   ],
   "source": [
    "def load_models():    \n",
    "    _DOWNLOAD_URL_PREFIX = 'http://download.tensorflow.org/models/'\n",
    "    model_dir = '../models/'\n",
    "    _MODEL_URLS = {\n",
    "        'mobilenetv2_coco_voctrainaug':\n",
    "            'deeplabv3_mnv2_pascal_train_aug_2018_01_29.tar.gz',\n",
    "        'mobilenetv2_coco_voctrainval':\n",
    "            'deeplabv3_mnv2_pascal_trainval_2018_01_29.tar.gz',\n",
    "        'xception_coco_voctrainaug':\n",
    "            'deeplabv3_pascal_train_aug_2018_01_04.tar.gz',\n",
    "        'xception_coco_voctrainval':\n",
    "            'deeplabv3_pascal_trainval_2018_01_04.tar.gz',\n",
    "    }\n",
    "    models = dict()\n",
    "    for modelname, tarname in _MODEL_URLS.items():\n",
    "        download_path = os.path.join(model_dir, tarname)\n",
    "        if not os.path.isfile(download_path):\n",
    "            print('downloading {}, this might take a while...'.format(modelname))\n",
    "            urllib.request.urlretrieve(_DOWNLOAD_URL_PREFIX + _MODEL_URLS[modelname],\n",
    "                               download_path)\n",
    "            print('download completed!')\n",
    "            \n",
    "        else:\n",
    "            print(\"model already present at {}\".format(download_path))\n",
    "        \n",
    "        print('Loading model {}...'.format(modelname))\n",
    "        models[modelname] = DeepLabModel.DeepLabModel(download_path)\n",
    "        print('{} loaded successfully!'.format(modelname))\n",
    "    return models\n",
    "models = load_models()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Defining label colors and names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "LABEL_NAMES = np.asarray([\n",
    "    'background', 'aeroplane', 'bicycle', 'bird', 'boat', 'bottle', 'bus',\n",
    "    'car', 'cat', 'chair', 'cow', 'diningtable', 'dog', 'horse', 'motorbike',\n",
    "    'person', 'pottedplant', 'sheep', 'sofa', 'train', 'tv'\n",
    "])\n",
    "FULL_LABEL_MAP = np.arange(len(LABEL_NAMES)).reshape(len(LABEL_NAMES), 1)\n",
    "FULL_COLOR_MAP = DeepLabModel.label_to_color_image(FULL_LABEL_MAP)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initializing Agents and Mediator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Defining agent parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded = pd.read_csv('params.csv', index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "68681b073dd948c1a17dcc599e2c260b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(VBox(children=(Label(value='xception_coco_voctrainaug'), FloatSlider(value=0.9378535272418737, …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "alphasliders = {m:[FloatSlider(description=l, min=0., max=1., step=0.01, value=loaded.loc[m][l]) for l in LABEL_NAMES] for m in models.keys()}\n",
    "sliders = [VBox([Label(model)]+alphasliders[model]) for model in alphasliders.keys()]\n",
    "HBox(sliders)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_proposals(task, proposals, utilities):\n",
    "        plt.figure(figsize=(16,9), dpi=300)\n",
    "        # Finding all the labels that appear in the proposals for the legend\n",
    "        unique_labels = np.array([], dtype=np.int)\n",
    "        for p in proposals:\n",
    "            unique_labels = np.union1d(unique_labels, np.unique(p))\n",
    "        unique_labels = unique_labels[unique_labels!=255] # We ignore the void label (see VOC2012 docs)\n",
    "                \n",
    "        max_cols = len(proposals)+2\n",
    "\n",
    "        grid_spec = gridspec.GridSpec(1, max_cols, width_ratios= [6] + [6 for i in proposals]+ [2])\n",
    "        # Show input\n",
    "        plt.subplot(grid_spec[0])\n",
    "        plt.imshow(task)\n",
    "        plt.axis('off')\n",
    "        plt.title('Input')\n",
    "\n",
    "        for p, prop in enumerate(proposals):\n",
    "            plt.subplot(grid_spec[p+1])\n",
    "            plt.imshow(DeepLabModel.label_to_color_image(prop).astype(np.uint8))\n",
    "            plt.axis('off')\n",
    "            plt.title('Model {}'.format(p+1))\n",
    "\n",
    "        ax = plt.subplot(grid_spec[max_cols-1])\n",
    "        plt.imshow(\n",
    "            FULL_COLOR_MAP[unique_labels].astype(np.uint8), interpolation='nearest', aspect=0.3)\n",
    "        ax.yaxis.tick_right()\n",
    "        plt.yticks(range(len(unique_labels)), LABEL_NAMES[unique_labels])\n",
    "        plt.xticks([], [])\n",
    "        ax.tick_params(width=0.0)\n",
    "        plt.grid(False)\n",
    "        plt.show()\n",
    "\n",
    "def show_agreement(agreement, i):\n",
    "        labels = agreement.keys()\n",
    "        plt.figure(figsize=(16,9), dpi=300)\n",
    "        for lpos, lab in enumerate(labels):\n",
    "            agr = agreement[lab]\n",
    "            plt.subplot(1, len(labels), lpos+1)\n",
    "            plt.title(\"Agreement {} for label {}\".format(i, LABEL_NAMES[lab]))\n",
    "            plt.set_cmap('gray')\n",
    "            plt.axis('off')\n",
    "            plt.imshow(agr)\n",
    "            \n",
    "def show_stats(log):\n",
    "    plt.figure(figsize=(16,9))\n",
    "    plt.subplot(1, 2, 1)\n",
    "    util = np.array(log['util']).transpose()\n",
    "    plt.title(\"Utility\")\n",
    "    for a, agent_util in enumerate(util):\n",
    "        plt.plot(agent_util, label=\"Agent {}\".format(a+1))\n",
    "    plt.legend()\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.title(\"Remaining Pixels %\")\n",
    "    progress = np.array(log['remaining_points'])\n",
    "    progress = progress / progress[0]\n",
    "    plt.plot(progress)\n",
    "    \n",
    "\n",
    "def get_remaining_points(agreement):\n",
    "    stacked = np.stack([a for k, a in agreement.items()])\n",
    "    return np.count_nonzero(np.logical_and(stacked!=0, stacked!=1))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Demo on a random Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download an image and start negotiation\n",
    "url = 'http://farm8.static.flickr.com/7920/47425338881_de208df2ff_m.jpg'\n",
    "#url = 'https://cdn.vox-cdn.com/uploads/chorus_asset/file/8327269/Screen_Shot_2017_04_12_at_3.54.13_PM.png'\n",
    "#url = 'https://proxy.duckduckgo.com/iu/?u=https%3A%2F%2Fimages.fastcompany.net%2Fimage%2Fupload%2Fw_596%2Cc_limit%2Cq_auto%3Abest%2Cf_auto%2Cfl_lossy%2Ffc%2F1683481-inline-s-2-dog-tv-share-the-remote-control.jpg&f=1'\n",
    "#url = 'https://www.zastavki.com/pictures/originals/2013/People_Shadows_of_people_looked_047805_.jpg'\n",
    "f = urllib.request.urlopen(url)\n",
    "jpeg_str = f.read()\n",
    "original_im = Image.open(BytesIO(jpeg_str))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mediator Running\n",
      "(342, 513)\n",
      "(342, 513)\n",
      "(342, 513)\n",
      "(342, 513)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1ced8adce8d3492aa6cc6c1b5279cca7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Label(value='Current Step')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "822db29a50cf41d3b6e6c9c5da87dc4c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "IntProgress(value=0, max=1)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "63b5911d1bc4407f801ecdc0824fa516",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Label(value='Total Progress')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8a9bdfa630fd44ce91af195c7e2ce72b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, max=1.0)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7f2b86461e2d441c92b56c306d594201",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(IntText(value=1, description='n'), Output()), _dom_classes=('widget-interact',))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "alpha = {m: [slider.value for slider in alphasliders[m]] for m in alphasliders.keys()}\n",
    "agents = [Agent(modelname, model, alpha[modelname]) for modelname, model in models.items()]\n",
    "mediator = Mediator(agents)\n",
    "print(\"Mediator Running\")\n",
    "log = {'util':[], 'remaining_points':list()}\n",
    "init_proposal, init_utilities = mediator.start_new_task(original_im)  \n",
    "next_step = enumerate(mediator.negotiation(timeout=10000))\n",
    "display(Label(\"Current Step\"))\n",
    "step_progress = IntProgress(max=1)\n",
    "display(step_progress)\n",
    "display(Label(\"Total Progress\"))\n",
    "pixel_progress = FloatProgress(max=1.0)\n",
    "display(pixel_progress)\n",
    "grid_spec = None\n",
    "from ipywidgets import IntText\n",
    "\n",
    "def run_negotiation(n):\n",
    "    if n<len(log['remaining_points']):\n",
    "        return\n",
    "    step_progress.max = n\n",
    "    for i, (agreement, proposals, utilities) in next_step:\n",
    "        step_progress.value = i\n",
    "        current_rp = get_remaining_points(agreement)\n",
    "        log['util'].append(utilities.mean(axis=2).mean(axis=1))\n",
    "        log['remaining_points'].append(current_rp)\n",
    "        pixel_progress.value = 1 - current_rp/log['remaining_points'][0]\n",
    "        #print(\"Done {} of {}, ({})%\".format(current_rp, log['remaining_points'][0], pixel_progress.value))\n",
    "        if i == n-1 or pixel_progress.value >= 0.99:\n",
    "            show_proposals(original_im, init_proposal, init_utilities)\n",
    "            show_agreement(agreement, i)\n",
    "            show_proposals(original_im, proposals, utilities)\n",
    "            show_stats(log)\n",
    "            return\n",
    "\n",
    "interact(run_negotiation, n=IntText(value=1));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "UsageError: Line magic function `%tensorboard` not found.\n"
     ]
    }
   ],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Fetch argument 'logits:0' cannot be interpreted as a Tensor. (\"The name 'logits:0' refers to a Tensor which does not exist. The operation, 'logits', does not exist in the graph.\")",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, fetches, contraction_fn)\u001b[0m\n\u001b[1;32m    299\u001b[0m         self._unique_fetches.append(ops.get_default_graph().as_graph_element(\n\u001b[0;32m--> 300\u001b[0;31m             fetch, allow_tensor=True, allow_operation=True))\n\u001b[0m\u001b[1;32m    301\u001b[0m       \u001b[0;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mas_graph_element\u001b[0;34m(self, obj, allow_tensor, allow_operation)\u001b[0m\n\u001b[1;32m   3486\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_finalized\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3487\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_as_graph_element_locked\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mallow_tensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mallow_operation\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3488\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36m_as_graph_element_locked\u001b[0;34m(self, obj, allow_tensor, allow_operation)\u001b[0m\n\u001b[1;32m   3531\u001b[0m                          \u001b[0;34m\"exist. The operation, %s, does not exist in the \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3532\u001b[0;31m                          \"graph.\" % (repr(name), repr(op_name)))\n\u001b[0m\u001b[1;32m   3533\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: \"The name 'logits:0' refers to a Tensor which does not exist. The operation, 'logits', does not exist in the graph.\"",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-1bff39d9e3f4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodels\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'mobilenetv2_coco_voctrainaug'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moriginal_im\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/home/DCSeg/src/DeepLabModel.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, image)\u001b[0m\n\u001b[1;32m     60\u001b[0m     batch_seg_map = self.sess.run(\n\u001b[1;32m     61\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOUTPUT_TENSOR_NAME\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 62\u001b[0;31m         feed_dict={self.INPUT_TENSOR_NAME: [np.asarray(resized_image)]})\n\u001b[0m\u001b[1;32m     63\u001b[0m     \u001b[0mseg_map\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch_seg_map\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mresized_image\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mseg_map\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    927\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    928\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 929\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    930\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    931\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1135\u001b[0m     \u001b[0;31m# Create a fetch handler to take care of the structure of fetches.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1136\u001b[0m     fetch_handler = _FetchHandler(\n\u001b[0;32m-> 1137\u001b[0;31m         self._graph, fetches, feed_dict_tensor, feed_handles=feed_handles)\n\u001b[0m\u001b[1;32m   1138\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1139\u001b[0m     \u001b[0;31m# Run request and get response.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, graph, fetches, feeds, feed_handles)\u001b[0m\n\u001b[1;32m    469\u001b[0m     \"\"\"\n\u001b[1;32m    470\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mgraph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_default\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 471\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fetch_mapper\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_FetchMapper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfor_fetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    472\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fetches\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    473\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_targets\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mfor_fetch\u001b[0;34m(fetch)\u001b[0m\n\u001b[1;32m    269\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfetch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor_type\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    270\u001b[0m           \u001b[0mfetches\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcontraction_fn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfetch_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfetch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 271\u001b[0;31m           \u001b[0;32mreturn\u001b[0m \u001b[0m_ElementFetchMapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfetches\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcontraction_fn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    272\u001b[0m     \u001b[0;31m# Did not find anything.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    273\u001b[0m     raise TypeError('Fetch argument %r has invalid type %r' % (fetch,\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, fetches, contraction_fn)\u001b[0m\n\u001b[1;32m    308\u001b[0m       \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    309\u001b[0m         raise ValueError('Fetch argument %r cannot be interpreted as a '\n\u001b[0;32m--> 310\u001b[0;31m                          'Tensor. (%s)' % (fetch, str(e)))\n\u001b[0m\u001b[1;32m    311\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_contraction_fn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcontraction_fn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    312\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Fetch argument 'logits:0' cannot be interpreted as a Tensor. (\"The name 'logits:0' refers to a Tensor which does not exist. The operation, 'logits', does not exist in the graph.\")"
     ]
    }
   ],
   "source": [
    "models['mobilenetv2_coco_voctrainaug'].run(original_im)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'mobilenetv2_coco_voctrainaug': <DeepLabModel.DeepLabModel at 0x7f0556e4dac8>,\n",
       " 'mobilenetv2_coco_voctrainval': <DeepLabModel.DeepLabModel at 0x7f04aa24d7b8>,\n",
       " 'xception_coco_voctrainaug': <DeepLabModel.DeepLabModel at 0x7f0556e4d550>,\n",
       " 'xception_coco_voctrainval': <DeepLabModel.DeepLabModel at 0x7f059c0cdeb8>}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
