{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Automatic pdb calling has been turned OFF\n"
     ]
    }
   ],
   "source": [
    "import DeepLabModel\n",
    "import os, urllib\n",
    "from PIL import Image\n",
    "from io import BytesIO\n",
    "import numpy as np\n",
    "from skimage.io import imshow\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import gridspec\n",
    "from ipywidgets import FloatSlider, interact, fixed, HBox, VBox, Label, Button, Output, IntProgress, FloatProgress\n",
    "%pdb 0\n",
    "plt.rcParams['figure.max_open_warning'] = False\n",
    "import pandas as pd\n",
    "import IPython\n",
    "%matplotlib inline\n",
    "from skimage.measure import label\n",
    "\n",
    "from DCSegUtils import softmax"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Combining Segmentation models using Cooperative Negotiation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Agent():\n",
    "    def __init__(self, agentname, model, alpha):\n",
    "        self.agentname=agentname\n",
    "        self.model=model\n",
    "        self.task = None\n",
    "        self.initial_proposal = None\n",
    "        self.alpha = alpha\n",
    "        \n",
    "    def new_task(self, image):\n",
    "        self.task, logits = self.model.run(image)\n",
    "        logits=logits[:self.task.size[1], :self.task.size[0], ...] # Otherwise logits are a square matrix\n",
    "        self.initial_proposal = softmax(logits, axis=-1)\n",
    "        return self.initial_proposal\n",
    "    \n",
    "    def utility(self, proposal):\n",
    "        'Returns a utility of shape (labels) between a proposal and self.optimal'\n",
    "        return np.array([np.linalg.norm(self.optimal[...,l]-proposal[...,l]) for l in range(self.optimal.shape[-1])])\n",
    "    \n",
    "    def propose(self, agreement):\n",
    "        print(self.algeement.shape)\n",
    "        \n",
    "\n",
    "                \n",
    "                \n",
    "        proposal = proposal.astype(np.int)\n",
    "        utility = self.utility(proposal)   \n",
    "        return proposal, utility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Mediator():\n",
    "    def __init__(self, agents):\n",
    "        self.agents = agents\n",
    "        self.last_step=0\n",
    "        \n",
    "    def start_new_task(self, image):\n",
    "        self.task = image\n",
    "        received_proposals = [agent.new_task(self.task) for agent in self.agents] # ((p0, u0), (p1, u1), ...)\n",
    "        self.initial_proposals = np.array([a[0] for a in received_proposals]) # Shape (agents, h, w, labels)\n",
    "        utilities_array = np.array([a[1] for a in received_proposals]) # Shape (agents, labels)\n",
    "        # To make it possible to multiply proposal (agents, h, w, labels) and utilities we have to expand dimensions (agents, 1, 1, labels)\n",
    "        self.initial_utilities = np.expand_dims(np.expand_dims(utilities_array, axis=1), axis=1) # Shape: (agents, 1, 1, labels)\n",
    "        self.last_proposals = self.initial_proposals\n",
    "        self.last_utilities = self.initial_utilities\n",
    "        return self.last_proposals, self.last_utilities\n",
    "\n",
    "        \n",
    "    def negotiation(self, timeout = 1000):\n",
    "        \n",
    "        for i in range(self.last_step, self.last_step+timeout):\n",
    "            self.last_step = i            \n",
    "            self.last_agreement = np.divide(np.sum(self.last_proposals*(1+self.last_utilities), axis=0), np.sum(1+self.last_utilities, axis=0))\n",
    "            \n",
    "            # Propose the new agreement to the agents\n",
    "            received_proposals = [agent.propose(self.last_agreement) for agent in self.agents] # ((p0, u0), (p1, u1), ...)\n",
    "            self.last_proposals = np.array([a[0] for a in received_proposals]) # Shape (agents, h, w)\n",
    "            utilities_array = np.array([a[1] for a in received_proposals]) # Shape (agents, labels)\n",
    "            self.last_utilities = np.expand_dims(np.expand_dims(utilities_array, axis=1), axis=1) # Shape: (agents, 1, 1, labels)\n",
    "\n",
    "            yield agreement, self.last_proposals, self.last_utilities\n",
    "        return agreement, self.last_proposals, self.last_utilities"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading Deep Learning Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model already present at ../models/deeplabv3_mnv2_pascal_train_aug_2018_01_29.tar.gz\n",
      "Loading model mobilenetv2_coco_voctrainaug...\n",
      "mobilenetv2_coco_voctrainaug loaded successfully!\n",
      "model already present at ../models/deeplabv3_pascal_trainval_2018_01_04.tar.gz\n",
      "Loading model xception_coco_voctrainval...\n",
      "xception_coco_voctrainval loaded successfully!\n",
      "model already present at ../models/deeplabv3_mnv2_pascal_trainval_2018_01_29.tar.gz\n",
      "Loading model mobilenetv2_coco_voctrainval...\n",
      "mobilenetv2_coco_voctrainval loaded successfully!\n",
      "model already present at ../models/deeplabv3_pascal_train_aug_2018_01_04.tar.gz\n",
      "Loading model xception_coco_voctrainaug...\n",
      "xception_coco_voctrainaug loaded successfully!\n"
     ]
    }
   ],
   "source": [
    "def load_models():    \n",
    "    _DOWNLOAD_URL_PREFIX = 'http://download.tensorflow.org/models/'\n",
    "    model_dir = '../models/'\n",
    "    _MODEL_URLS = {\n",
    "        'mobilenetv2_coco_voctrainaug':\n",
    "            'deeplabv3_mnv2_pascal_train_aug_2018_01_29.tar.gz',\n",
    "        'mobilenetv2_coco_voctrainval':\n",
    "            'deeplabv3_mnv2_pascal_trainval_2018_01_29.tar.gz',\n",
    "        'xception_coco_voctrainaug':\n",
    "            'deeplabv3_pascal_train_aug_2018_01_04.tar.gz',\n",
    "        'xception_coco_voctrainval':\n",
    "            'deeplabv3_pascal_trainval_2018_01_04.tar.gz',\n",
    "    }\n",
    "    models = dict()\n",
    "    for modelname, tarname in _MODEL_URLS.items():\n",
    "        download_path = os.path.join(model_dir, tarname)\n",
    "        if not os.path.isfile(download_path):\n",
    "            print('downloading {}, this might take a while...'.format(modelname))\n",
    "            urllib.request.urlretrieve(_DOWNLOAD_URL_PREFIX + _MODEL_URLS[modelname],\n",
    "                               download_path)\n",
    "            print('download completed!')\n",
    "            \n",
    "        else:\n",
    "            print(\"model already present at {}\".format(download_path))\n",
    "        \n",
    "        print('Loading model {}...'.format(modelname))\n",
    "        models[modelname] = DeepLabModel.DeepLabModel(download_path)\n",
    "        print('{} loaded successfully!'.format(modelname))\n",
    "    return models\n",
    "models = load_models()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Defining label colors and names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "LABEL_NAMES = np.asarray([\n",
    "    'background', 'aeroplane', 'bicycle', 'bird', 'boat', 'bottle', 'bus',\n",
    "    'car', 'cat', 'chair', 'cow', 'diningtable', 'dog', 'horse', 'motorbike',\n",
    "    'person', 'pottedplant', 'sheep', 'sofa', 'train', 'tv'\n",
    "])\n",
    "FULL_LABEL_MAP = np.arange(len(LABEL_NAMES)).reshape(len(LABEL_NAMES), 1)\n",
    "FULL_COLOR_MAP = DeepLabModel.label_to_color_image(FULL_LABEL_MAP)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initializing Agents and Mediator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Defining agent parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded = pd.read_csv('params.csv', index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7a0fa83167684b21b7d45effec3e7fe4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(VBox(children=(Label(value='mobilenetv2_coco_voctrainaug'), FloatSlider(value=0.917627309369092â€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "alphasliders = {m:[FloatSlider(description=l, min=0., max=1., step=0.01, value=loaded.loc[m][l]) for l in LABEL_NAMES] for m in models.keys()}\n",
    "sliders = [VBox([Label(model)]+alphasliders[model]) for model in alphasliders.keys()]\n",
    "HBox(sliders)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_proposals(task, proposals, utilities):\n",
    "        plt.figure(figsize=(16,9), dpi=300)\n",
    "        # Finding all the labels that appear in the proposals for the legend\n",
    "        unique_labels = np.array([], dtype=np.int)\n",
    "        for p in proposals:\n",
    "            unique_labels = np.union1d(unique_labels, np.unique(p))\n",
    "        unique_labels = unique_labels[unique_labels!=255] # We ignore the void label (see VOC2012 docs)\n",
    "                \n",
    "        max_cols = len(proposals)+2\n",
    "\n",
    "        grid_spec = gridspec.GridSpec(1, max_cols, width_ratios= [6] + [6 for i in proposals]+ [2])\n",
    "        # Show input\n",
    "        plt.subplot(grid_spec[0])\n",
    "        plt.imshow(task)\n",
    "        plt.axis('off')\n",
    "        plt.title('Input')\n",
    "\n",
    "        for p, prop in enumerate(proposals):\n",
    "            plt.subplot(grid_spec[p+1])\n",
    "            plt.imshow(DeepLabModel.label_to_color_image(prop).astype(np.uint8))\n",
    "            plt.axis('off')\n",
    "            plt.title('Model {}'.format(p+1))\n",
    "\n",
    "        ax = plt.subplot(grid_spec[max_cols-1])\n",
    "        plt.imshow(\n",
    "            FULL_COLOR_MAP[unique_labels].astype(np.uint8), interpolation='nearest', aspect=0.3)\n",
    "        ax.yaxis.tick_right()\n",
    "        plt.yticks(range(len(unique_labels)), LABEL_NAMES[unique_labels])\n",
    "        plt.xticks([], [])\n",
    "        ax.tick_params(width=0.0)\n",
    "        plt.grid(False)\n",
    "        plt.show()\n",
    "\n",
    "def show_agreement(agreement, i):\n",
    "        labels = agreement.keys()\n",
    "        plt.figure(figsize=(16,9), dpi=300)\n",
    "        for lpos, lab in enumerate(labels):\n",
    "            agr = agreement[lab]\n",
    "            plt.subplot(1, len(labels), lpos+1)\n",
    "            plt.title(\"Agreement {} for label {}\".format(i, LABEL_NAMES[lab]))\n",
    "            plt.set_cmap('gray')\n",
    "            plt.axis('off')\n",
    "            plt.imshow(agr)\n",
    "            \n",
    "def show_stats(log):\n",
    "    plt.figure(figsize=(16,9))\n",
    "    plt.subplot(1, 2, 1)\n",
    "    util = np.array(log['util']).transpose()\n",
    "    plt.title(\"Utility\")\n",
    "    for a, agent_util in enumerate(util):\n",
    "        plt.plot(agent_util, label=\"Agent {}\".format(a+1))\n",
    "    plt.legend()\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.title(\"Remaining Pixels %\")\n",
    "    progress = np.array(log['remaining_points'])\n",
    "    progress = progress / progress[0]\n",
    "    plt.plot(progress)\n",
    "    \n",
    "\n",
    "def get_remaining_points(agreement):\n",
    "    stacked = np.stack([a for k, a in agreement.items()])\n",
    "    return np.count_nonzero(np.logical_and(stacked!=0, stacked!=1))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Demo on a random Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download an image and start negotiation\n",
    "url = 'http://farm8.static.flickr.com/7920/47425338881_de208df2ff_m.jpg'\n",
    "#url = 'https://cdn.vox-cdn.com/uploads/chorus_asset/file/8327269/Screen_Shot_2017_04_12_at_3.54.13_PM.png'\n",
    "#url = 'https://proxy.duckduckgo.com/iu/?u=https%3A%2F%2Fimages.fastcompany.net%2Fimage%2Fupload%2Fw_596%2Cc_limit%2Cq_auto%3Abest%2Cf_auto%2Cfl_lossy%2Ffc%2F1683481-inline-s-2-dog-tv-share-the-remote-control.jpg&f=1'\n",
    "#url = 'https://www.zastavki.com/pictures/originals/2013/People_Shadows_of_people_looked_047805_.jpg'\n",
    "f = urllib.request.urlopen(url)\n",
    "jpeg_str = f.read()\n",
    "original_im = Image.open(BytesIO(jpeg_str))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mediator Running\n",
      "(342, 513, 21)\n",
      "(342, 513, 21)\n",
      "(342, 513, 21)\n",
      "(342, 513, 21)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cf819702b9154a0093b0e457f04bc2b8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Label(value='Current Step')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9bbae6a75fdf43e7ab0d3ba2692407f1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "IntProgress(value=0, max=1)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "38493d208b514775abaaa1c53aa3531a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Label(value='Total Progress')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8dc9c342987c43aeb133e4625476129d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, max=1.0)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bc2609405b9d4a80ae8f563aa685f5fe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(IntText(value=1, description='n'), Output()), _dom_classes=('widget-interact',))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "alpha = {m: [slider.value for slider in alphasliders[m]] for m in alphasliders.keys()}\n",
    "agents = [Agent(modelname, model, alpha[modelname]) for modelname, model in models.items()]\n",
    "mediator = Mediator(agents)\n",
    "print(\"Mediator Running\")\n",
    "log = {'util':[], 'remaining_points':list()}\n",
    "init_proposal, init_utilities = mediator.start_new_task(original_im)  \n",
    "next_step = enumerate(mediator.negotiation(timeout=10000))\n",
    "display(Label(\"Current Step\"))\n",
    "step_progress = IntProgress(max=1)\n",
    "display(step_progress)\n",
    "display(Label(\"Total Progress\"))\n",
    "pixel_progress = FloatProgress(max=1.0)\n",
    "display(pixel_progress)\n",
    "grid_spec = None\n",
    "from ipywidgets import IntText\n",
    "\n",
    "def run_negotiation(n):\n",
    "    if n<len(log['remaining_points']):\n",
    "        return\n",
    "    step_progress.max = n\n",
    "    for i, (agreement, proposals, utilities) in next_step:\n",
    "        step_progress.value = i\n",
    "        current_rp = get_remaining_points(agreement)\n",
    "        log['util'].append(utilities.mean(axis=2).mean(axis=1))\n",
    "        log['remaining_points'].append(current_rp)\n",
    "        pixel_progress.value = 1 - current_rp/log['remaining_points'][0]\n",
    "        #print(\"Done {} of {}, ({})%\".format(current_rp, log['remaining_points'][0], pixel_progress.value))\n",
    "        if i == n-1 or pixel_progress.value >= 0.99:\n",
    "            show_proposals(original_im, init_proposal, init_utilities)\n",
    "            show_agreement(agreement, i)\n",
    "            show_proposals(original_im, proposals, utilities)\n",
    "            show_stats(log)\n",
    "            return\n",
    "\n",
    "interact(run_negotiation, n=IntText(value=1));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4, 1, 1, 21)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "UsageError: Line magic function `%tensorboard` not found.\n"
     ]
    }
   ],
   "source": [
    "def export_model_graph(model):\n",
    "    import tensorflow as tf\n",
    "    from tensorflow.python.summary.writer.writer import FileWriter\n",
    "\n",
    "    logdir = 'tmpgraphs/'\n",
    "    FileWriter(logdir, graph=model.graph).close()\n",
    "    %tensorboard --logdir logs/train\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = mediator.last_proposals\n",
    "u = mediator.last_utilities\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2.9910801e+01, 1.6184177e-01, 1.0312250e-01, 5.7711524e-01,\n",
       "       7.1680403e+00, 2.1571117e-02, 9.2500865e-02, 1.2548501e+00,\n",
       "       5.1552469e-01, 4.4195695e+00, 4.0696907e-01, 3.5089332e-01,\n",
       "       5.5626054e+00, 2.5385084e+01, 6.9904458e-03, 1.5834814e+01,\n",
       "       9.5259346e-02, 1.4908504e-01, 2.8965683e+00, 5.0728178e-01,\n",
       "       1.0242431e-01], dtype=float32)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agents[0].utility(agr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
