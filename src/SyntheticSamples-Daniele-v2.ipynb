{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No GPU found, model running on CPU\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import NegotiationTools as negtools\n",
    "import matplotlib.pyplot as plt\n",
    "from skimage.draw import rectangle\n",
    "import skimage as skim\n",
    "import pandas as pd\n",
    "import seaborn as sb\n",
    "import Experiments as exp\n",
    "import math\n",
    "\n",
    "stats = negtools.StatisticsLogger()\n",
    "nt = negtools.NegTools()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Templates\n",
    "A template is the basic form of the ground truth and predictions. It is then converted into a prediction by replicating it for each label/agent. Different objects are labeled with integer numbers, with 0 being the background."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "W = 25\n",
    "H = 25\n",
    "W2 = 5\n",
    "H2 = 5\n",
    "templates = dict()\n",
    "\n",
    "templates['pixel_spot'] = np.zeros((W, H), dtype=np.uint8)\n",
    "templates['pixel_spot'][2,2] = 1\n",
    "\n",
    "templates['single_sq'] = np.zeros((W, H), dtype=np.uint8)\n",
    "templates['single_sq'][tuple(rectangle(start=(5,5), extent=(15,15), shape=(W,H)))] = 1\n",
    "\n",
    "templates['multi_sq'] = np.zeros((W, H), dtype=np.uint8)\n",
    "templates['multi_sq'][1,1] = 1\n",
    "templates['multi_sq'][1,3] = 2\n",
    "templates['multi_sq'][3,1] = 3\n",
    "templates['multi_sq'][3,3] = 4\n",
    "\n",
    "templates['bin_blob'] = np.zeros((W, H), dtype=np.uint8)\n",
    "templates['bin_blob'][tuple(rectangle(start=(5,5), extent=(15,15), shape=(W,H)))] = 1\n",
    "\n",
    "templates['bin_chk'] = np.zeros((W, H), dtype=np.uint8)\n",
    "is_one = True\n",
    "for i in range(0,W,W2):\n",
    "    for j in range(0,H,H2):\n",
    "        if is_one is True:\n",
    "            templates['bin_chk'][tuple(rectangle(start=(i,j), extent=(W2,H2), shape=(W,H)))] = 1\n",
    "        is_one = not is_one\n",
    "        \n",
    "n_class = 4\n",
    "blobs_w = 8\n",
    "blobs_h = 8\n",
    "w_off = 2\n",
    "h_off = 2\n",
    "blobs_val = 1\n",
    "\n",
    "templates['blobs'] = np.zeros((W, H), dtype=np.uint8)\n",
    "for i in range(0,W,blobs_w+2*w_off):\n",
    "    for j in range(0,H,blobs_h+2*h_off):\n",
    "        templates['blobs'][tuple(rectangle(start=(i+w_off,j+h_off), extent=(blobs_w,blobs_h), shape=(W,H)))] = blobs_val\n",
    "        blobs_val = blobs_val+1\n",
    "\n",
    "W = 25\n",
    "H = 25\n",
    "CHK_W = 5\n",
    "CHK_H = 5\n",
    "val = 0\n",
    "n_class = 4\n",
    "templates['chk'] = np.zeros((W, H), dtype=np.uint8)\n",
    "is_one = True\n",
    "for i in range(0,W,CHK_W):\n",
    "    for j in range(0,H,CHK_H):\n",
    "        templates['chk'][tuple(rectangle(start=(i,j), extent=(CHK_W,CHK_H), shape=(W,H)))] = val + 1\n",
    "        val = (val + 1) % n_class\n",
    "\n",
    "templates['checkerboard'] = skim.data.checkerboard().astype(np.bool).astype(np.float32)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 8 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "for i, (name, templ) in enumerate(templates.items()):\n",
    "    plt.subplot(2, math.ceil(len(templates.items())/2), i+1)\n",
    "    plt.imshow(templ)\n",
    "    plt.title(name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def agent_binary_balanced(mu, std):\n",
    "\n",
    "    mu_mat = [[mu, 1.-mu],\n",
    "           [1.-mu, mu]]\n",
    "    std_mat = np.ones_like(mu_mat)*std\n",
    "    return (np.asarray(mu_mat),np.asarray(std_mat))\n",
    "\n",
    "def agent_binary_unbalanced(mu_1, mu_2, std):\n",
    "    \n",
    "    mu_mat = [[mu_1, 1.-mu_1],\n",
    "           [1.-mu_2, mu_2]]\n",
    "    std_mat = np.ones_like(mu_mat)*std\n",
    "    return (np.asarray(mu_mat),np.asarray(std_mat))\n",
    "\n",
    "\n",
    "def agent_expert(mu_star, mu, std, c_star, n_labels):\n",
    "    '''\n",
    "    :param mu_star - \"competence\" on expertise class\n",
    "    :param mu - \"competence\" on non expertise classes\n",
    "    :param std - standard deviation\n",
    "    :param c_star - index of expertise class\n",
    "    :param n_labels - number of labels\n",
    "    '''\n",
    "    samp_mu = np.random.normal(loc=mu, scale=std)\n",
    "    samp_mu_star = np.random.normal(loc=mu_star, scale=std)\n",
    "    samp_c_star_others = (1. - samp_mu_star)/(n_labels - 1.)\n",
    "    samp_gamma = (1. - samp_c_star_others - samp_mu) / (n_labels-2.) if n_labels > 2 else 0\n",
    "\n",
    "    mat = list()\n",
    "    for t in range(n_labels):\n",
    "        row = list()\n",
    "        for p in range(n_labels):\n",
    "            if p == c_star and t == c_star:\n",
    "                row.append(samp_mu_star)\n",
    "            elif t == c_star or p == c_star:\n",
    "                row.append(samp_c_star_others)\n",
    "            elif p == t:\n",
    "                row.append(samp_mu)\n",
    "            else:\n",
    "                row.append(samp_gamma)\n",
    "        mat.append(row)\n",
    "    return np.asarray(mat)\n",
    "\n",
    "def generate_predictions(gt_template, mu_matrix, std_matrix):\n",
    "    prediction = list()\n",
    "    # Iterating through the columns (predicted classes) of agent matrix, filling the corresponding ground_truth areas with predictions\n",
    "    for pred_label in range(mu_matrix.shape[-1]):\n",
    "        label_image = np.zeros_like(gt_template)\n",
    "        for true_label in np.unique(gt_template):\n",
    "            agent_labels = np.random.normal(loc=np.ones_like(gt_template)*mu_matrix[true_label, pred_label],scale=np.ones_like(gt_template)*std_matrix[true_label,pred_label])\n",
    "            label_image = np.where(gt_template == true_label, agent_labels, label_image)\n",
    "        prediction.append(label_image)\n",
    "    return np.stack(prediction, axis=-1)\n",
    "\n",
    "def generate_ground_truth(gt_template, n_labels):\n",
    "    gt = list()\n",
    "    for l in range(n_labels):\n",
    "        gt_slice = np.where(gt_template==l, 1.0, 0.0)\n",
    "        gt.append(gt_slice)\n",
    "    return np.stack(gt, axis=-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Balanced (Binary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x13955c160>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(templates['bin_blob'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_LABELS = 2\n",
    "N_AGENTS = 3\n",
    "\n",
    "mu = 0.75\n",
    "std = 0.2\n",
    "c_star = 0\n",
    "template = templates['bin_blob']\n",
    "\n",
    "# Generating agents\n",
    "agents = [agent_binary_balanced(mu=mu, std=std) for a in range(N_AGENTS)]\n",
    "# Generating ground truth and predictions\n",
    "gt = generate_ground_truth(template, N_LABELS)\n",
    "predictions = np.stack([generate_predictions(template, mu_matrix, std_matrix) for (mu_matrix, std_matrix) in agents])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.78837195  0.27434022]\n",
      " [ 0.74384555  0.4683648 ]\n",
      " [ 0.77933936  0.68256513]\n",
      " [ 0.76471527  0.60839019]\n",
      " [ 0.64947891  0.21953834]\n",
      " [ 0.66230684  0.20010019]\n",
      " [ 0.59499945  0.21701312]\n",
      " [ 0.59471751  0.01937424]\n",
      " [ 0.71361049  0.25704437]\n",
      " [ 0.84888766  0.47146338]\n",
      " [ 0.91396686  0.03437546]\n",
      " [ 0.58118789  0.18187182]\n",
      " [ 0.77217668 -0.07086864]\n",
      " [ 0.9691393   0.2623055 ]\n",
      " [ 0.72091104  0.42940739]\n",
      " [ 0.92748697 -0.05701521]\n",
      " [ 0.34881157  0.20567119]\n",
      " [ 0.57380517  0.30034893]\n",
      " [ 0.72225054  0.16785516]\n",
      " [ 0.85180059  0.32040097]\n",
      " [ 0.6107936   0.03099966]\n",
      " [ 0.60963919  0.50717916]\n",
      " [ 0.65404201  0.02641276]\n",
      " [ 0.82240049  0.34786286]\n",
      " [ 0.78666316  0.28203008]]\n"
     ]
    }
   ],
   "source": [
    "print(predictions[1][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample 0 Timed out after 1000 steps\n",
      "Sample 0 Timed out after 1000 steps\n",
      "Sample 0 Timed out after 1000 steps\n",
      "Sample 0 Timed out after 1000 steps\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Label 0_f1-score</th>\n",
       "      <th>Label 0_precision</th>\n",
       "      <th>Label 0_recall</th>\n",
       "      <th>Label 0_support</th>\n",
       "      <th>Label 1_f1-score</th>\n",
       "      <th>Label 1_precision</th>\n",
       "      <th>Label 1_recall</th>\n",
       "      <th>Label 1_support</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>macro avg_f1-score</th>\n",
       "      <th>macro avg_precision</th>\n",
       "      <th>macro avg_recall</th>\n",
       "      <th>macro avg_support</th>\n",
       "      <th>weighted avg_f1-score</th>\n",
       "      <th>weighted avg_precision</th>\n",
       "      <th>weighted avg_recall</th>\n",
       "      <th>weighted avg_support</th>\n",
       "      <th>method</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.957447</td>\n",
       "      <td>0.957447</td>\n",
       "      <td>0.957447</td>\n",
       "      <td>47.0</td>\n",
       "      <td>0.916667</td>\n",
       "      <td>0.916667</td>\n",
       "      <td>0.916667</td>\n",
       "      <td>24.0</td>\n",
       "      <td>0.943662</td>\n",
       "      <td>0.937057</td>\n",
       "      <td>0.937057</td>\n",
       "      <td>0.937057</td>\n",
       "      <td>71.0</td>\n",
       "      <td>0.943662</td>\n",
       "      <td>0.943662</td>\n",
       "      <td>0.943662</td>\n",
       "      <td>71.0</td>\n",
       "      <td>Majority Voting</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.933333</td>\n",
       "      <td>0.976744</td>\n",
       "      <td>0.893617</td>\n",
       "      <td>47.0</td>\n",
       "      <td>0.884615</td>\n",
       "      <td>0.821429</td>\n",
       "      <td>0.958333</td>\n",
       "      <td>24.0</td>\n",
       "      <td>0.915493</td>\n",
       "      <td>0.908974</td>\n",
       "      <td>0.899086</td>\n",
       "      <td>0.925975</td>\n",
       "      <td>71.0</td>\n",
       "      <td>0.916865</td>\n",
       "      <td>0.924243</td>\n",
       "      <td>0.915493</td>\n",
       "      <td>71.0</td>\n",
       "      <td>Maximum Proposal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.989247</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.978723</td>\n",
       "      <td>47.0</td>\n",
       "      <td>0.979592</td>\n",
       "      <td>0.960000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>24.0</td>\n",
       "      <td>0.985915</td>\n",
       "      <td>0.984420</td>\n",
       "      <td>0.980000</td>\n",
       "      <td>0.989362</td>\n",
       "      <td>71.0</td>\n",
       "      <td>0.985983</td>\n",
       "      <td>0.986479</td>\n",
       "      <td>0.985915</td>\n",
       "      <td>71.0</td>\n",
       "      <td>Mean Proposal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.796610</td>\n",
       "      <td>0.661972</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>47.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>24.0</td>\n",
       "      <td>0.661972</td>\n",
       "      <td>0.398305</td>\n",
       "      <td>0.330986</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>71.0</td>\n",
       "      <td>0.527333</td>\n",
       "      <td>0.438207</td>\n",
       "      <td>0.661972</td>\n",
       "      <td>71.0</td>\n",
       "      <td>Negotiation - 3x3 Conv Entropy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.796610</td>\n",
       "      <td>0.661972</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>47.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>24.0</td>\n",
       "      <td>0.661972</td>\n",
       "      <td>0.398305</td>\n",
       "      <td>0.330986</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>71.0</td>\n",
       "      <td>0.527333</td>\n",
       "      <td>0.438207</td>\n",
       "      <td>0.661972</td>\n",
       "      <td>71.0</td>\n",
       "      <td>Negotiation - 5x5 Conv Entropy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.796610</td>\n",
       "      <td>0.661972</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>47.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>24.0</td>\n",
       "      <td>0.661972</td>\n",
       "      <td>0.398305</td>\n",
       "      <td>0.330986</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>71.0</td>\n",
       "      <td>0.527333</td>\n",
       "      <td>0.438207</td>\n",
       "      <td>0.661972</td>\n",
       "      <td>71.0</td>\n",
       "      <td>Negotiation - Mean Entropy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.958333</td>\n",
       "      <td>0.938776</td>\n",
       "      <td>0.978723</td>\n",
       "      <td>47.0</td>\n",
       "      <td>0.913043</td>\n",
       "      <td>0.954545</td>\n",
       "      <td>0.875000</td>\n",
       "      <td>24.0</td>\n",
       "      <td>0.943662</td>\n",
       "      <td>0.935688</td>\n",
       "      <td>0.946660</td>\n",
       "      <td>0.926862</td>\n",
       "      <td>71.0</td>\n",
       "      <td>0.943024</td>\n",
       "      <td>0.944106</td>\n",
       "      <td>0.943662</td>\n",
       "      <td>71.0</td>\n",
       "      <td>Negotiation - Pixelwise Entropy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.796610</td>\n",
       "      <td>0.661972</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>47.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>24.0</td>\n",
       "      <td>0.661972</td>\n",
       "      <td>0.398305</td>\n",
       "      <td>0.330986</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>71.0</td>\n",
       "      <td>0.527333</td>\n",
       "      <td>0.438207</td>\n",
       "      <td>0.661972</td>\n",
       "      <td>71.0</td>\n",
       "      <td>Weighted Mean - 3x3 Conv Entropy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.796610</td>\n",
       "      <td>0.661972</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>47.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>24.0</td>\n",
       "      <td>0.661972</td>\n",
       "      <td>0.398305</td>\n",
       "      <td>0.330986</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>71.0</td>\n",
       "      <td>0.527333</td>\n",
       "      <td>0.438207</td>\n",
       "      <td>0.661972</td>\n",
       "      <td>71.0</td>\n",
       "      <td>Weighted Mean - 5x5 Conv Entropy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.796610</td>\n",
       "      <td>0.661972</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>47.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>24.0</td>\n",
       "      <td>0.661972</td>\n",
       "      <td>0.398305</td>\n",
       "      <td>0.330986</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>71.0</td>\n",
       "      <td>0.527333</td>\n",
       "      <td>0.438207</td>\n",
       "      <td>0.661972</td>\n",
       "      <td>71.0</td>\n",
       "      <td>Weighted Mean - Mean Entropy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.958333</td>\n",
       "      <td>0.938776</td>\n",
       "      <td>0.978723</td>\n",
       "      <td>47.0</td>\n",
       "      <td>0.913043</td>\n",
       "      <td>0.954545</td>\n",
       "      <td>0.875000</td>\n",
       "      <td>24.0</td>\n",
       "      <td>0.943662</td>\n",
       "      <td>0.935688</td>\n",
       "      <td>0.946660</td>\n",
       "      <td>0.926862</td>\n",
       "      <td>71.0</td>\n",
       "      <td>0.943024</td>\n",
       "      <td>0.944106</td>\n",
       "      <td>0.943662</td>\n",
       "      <td>71.0</td>\n",
       "      <td>Weighted Mean - Pixelwise Entropy</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Label 0_f1-score  Label 0_precision  Label 0_recall  Label 0_support  \\\n",
       "0           0.957447           0.957447        0.957447             47.0   \n",
       "1           0.933333           0.976744        0.893617             47.0   \n",
       "2           0.989247           1.000000        0.978723             47.0   \n",
       "3           0.796610           0.661972        1.000000             47.0   \n",
       "4           0.796610           0.661972        1.000000             47.0   \n",
       "5           0.796610           0.661972        1.000000             47.0   \n",
       "6           0.958333           0.938776        0.978723             47.0   \n",
       "7           0.796610           0.661972        1.000000             47.0   \n",
       "8           0.796610           0.661972        1.000000             47.0   \n",
       "9           0.796610           0.661972        1.000000             47.0   \n",
       "10          0.958333           0.938776        0.978723             47.0   \n",
       "\n",
       "    Label 1_f1-score  Label 1_precision  Label 1_recall  Label 1_support  \\\n",
       "0           0.916667           0.916667        0.916667             24.0   \n",
       "1           0.884615           0.821429        0.958333             24.0   \n",
       "2           0.979592           0.960000        1.000000             24.0   \n",
       "3           0.000000           0.000000        0.000000             24.0   \n",
       "4           0.000000           0.000000        0.000000             24.0   \n",
       "5           0.000000           0.000000        0.000000             24.0   \n",
       "6           0.913043           0.954545        0.875000             24.0   \n",
       "7           0.000000           0.000000        0.000000             24.0   \n",
       "8           0.000000           0.000000        0.000000             24.0   \n",
       "9           0.000000           0.000000        0.000000             24.0   \n",
       "10          0.913043           0.954545        0.875000             24.0   \n",
       "\n",
       "    accuracy  macro avg_f1-score  macro avg_precision  macro avg_recall  \\\n",
       "0   0.943662            0.937057             0.937057          0.937057   \n",
       "1   0.915493            0.908974             0.899086          0.925975   \n",
       "2   0.985915            0.984420             0.980000          0.989362   \n",
       "3   0.661972            0.398305             0.330986          0.500000   \n",
       "4   0.661972            0.398305             0.330986          0.500000   \n",
       "5   0.661972            0.398305             0.330986          0.500000   \n",
       "6   0.943662            0.935688             0.946660          0.926862   \n",
       "7   0.661972            0.398305             0.330986          0.500000   \n",
       "8   0.661972            0.398305             0.330986          0.500000   \n",
       "9   0.661972            0.398305             0.330986          0.500000   \n",
       "10  0.943662            0.935688             0.946660          0.926862   \n",
       "\n",
       "    macro avg_support  weighted avg_f1-score  weighted avg_precision  \\\n",
       "0                71.0               0.943662                0.943662   \n",
       "1                71.0               0.916865                0.924243   \n",
       "2                71.0               0.985983                0.986479   \n",
       "3                71.0               0.527333                0.438207   \n",
       "4                71.0               0.527333                0.438207   \n",
       "5                71.0               0.527333                0.438207   \n",
       "6                71.0               0.943024                0.944106   \n",
       "7                71.0               0.527333                0.438207   \n",
       "8                71.0               0.527333                0.438207   \n",
       "9                71.0               0.527333                0.438207   \n",
       "10               71.0               0.943024                0.944106   \n",
       "\n",
       "    weighted avg_recall  weighted avg_support  \\\n",
       "0              0.943662                  71.0   \n",
       "1              0.915493                  71.0   \n",
       "2              0.985915                  71.0   \n",
       "3              0.661972                  71.0   \n",
       "4              0.661972                  71.0   \n",
       "5              0.661972                  71.0   \n",
       "6              0.943662                  71.0   \n",
       "7              0.661972                  71.0   \n",
       "8              0.661972                  71.0   \n",
       "9              0.661972                  71.0   \n",
       "10             0.943662                  71.0   \n",
       "\n",
       "                               method  \n",
       "0                     Majority Voting  \n",
       "1                    Maximum Proposal  \n",
       "2                       Mean Proposal  \n",
       "3      Negotiation - 3x3 Conv Entropy  \n",
       "4      Negotiation - 5x5 Conv Entropy  \n",
       "5          Negotiation - Mean Entropy  \n",
       "6     Negotiation - Pixelwise Entropy  \n",
       "7    Weighted Mean - 3x3 Conv Entropy  \n",
       "8    Weighted Mean - 5x5 Conv Entropy  \n",
       "9        Weighted Mean - Mean Entropy  \n",
       "10  Weighted Mean - Pixelwise Entropy  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "exp.run_experiment_on_list([predictions], [gt])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Unbalanced on C1 (Binary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_LABELS = 2\n",
    "N_AGENTS = 3\n",
    "\n",
    "mu_1 = 0.6\n",
    "mu_2 = 0.4\n",
    "std = 0.01\n",
    "c_star = 0\n",
    "template = templates['blob']\n",
    "\n",
    "# Generating agents\n",
    "agents = [agent_binary_unbalanced(mu_1=mu_1, mu_2=mu_2, std=std) for a in range(N_AGENTS)]\n",
    "# Generating ground truth and predictions\n",
    "gt = generate_ground_truth(template, N_LABELS)\n",
    "predictions = np.stack([generate_predictions(template, agent_matrix) for agent_matrix in agents])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample 0 Consensus Reached at step, current step: 0\n",
      "Sample 0 Consensus Reached at step, current step: 0\n",
      "Sample 0 Consensus Reached at step, current step: 0\n",
      "Sample 0 Consensus Reached at step, current step: 0\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Label 0_f1-score</th>\n",
       "      <th>Label 0_precision</th>\n",
       "      <th>Label 0_recall</th>\n",
       "      <th>Label 0_support</th>\n",
       "      <th>Label 1_f1-score</th>\n",
       "      <th>Label 1_precision</th>\n",
       "      <th>Label 1_recall</th>\n",
       "      <th>Label 1_support</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>macro avg_f1-score</th>\n",
       "      <th>macro avg_precision</th>\n",
       "      <th>macro avg_recall</th>\n",
       "      <th>macro avg_support</th>\n",
       "      <th>weighted avg_f1-score</th>\n",
       "      <th>weighted avg_precision</th>\n",
       "      <th>weighted avg_recall</th>\n",
       "      <th>weighted avg_support</th>\n",
       "      <th>method</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.780488</td>\n",
       "      <td>0.64</td>\n",
       "      <td>1.0</td>\n",
       "      <td>400.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>225.0</td>\n",
       "      <td>0.64</td>\n",
       "      <td>0.390244</td>\n",
       "      <td>0.32</td>\n",
       "      <td>0.5</td>\n",
       "      <td>625.0</td>\n",
       "      <td>0.499512</td>\n",
       "      <td>0.4096</td>\n",
       "      <td>0.64</td>\n",
       "      <td>625.0</td>\n",
       "      <td>Majority Voting</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.780488</td>\n",
       "      <td>0.64</td>\n",
       "      <td>1.0</td>\n",
       "      <td>400.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>225.0</td>\n",
       "      <td>0.64</td>\n",
       "      <td>0.390244</td>\n",
       "      <td>0.32</td>\n",
       "      <td>0.5</td>\n",
       "      <td>625.0</td>\n",
       "      <td>0.499512</td>\n",
       "      <td>0.4096</td>\n",
       "      <td>0.64</td>\n",
       "      <td>625.0</td>\n",
       "      <td>Maximum Proposal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.780488</td>\n",
       "      <td>0.64</td>\n",
       "      <td>1.0</td>\n",
       "      <td>400.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>225.0</td>\n",
       "      <td>0.64</td>\n",
       "      <td>0.390244</td>\n",
       "      <td>0.32</td>\n",
       "      <td>0.5</td>\n",
       "      <td>625.0</td>\n",
       "      <td>0.499512</td>\n",
       "      <td>0.4096</td>\n",
       "      <td>0.64</td>\n",
       "      <td>625.0</td>\n",
       "      <td>Mean Proposal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.780488</td>\n",
       "      <td>0.64</td>\n",
       "      <td>1.0</td>\n",
       "      <td>400.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>225.0</td>\n",
       "      <td>0.64</td>\n",
       "      <td>0.390244</td>\n",
       "      <td>0.32</td>\n",
       "      <td>0.5</td>\n",
       "      <td>625.0</td>\n",
       "      <td>0.499512</td>\n",
       "      <td>0.4096</td>\n",
       "      <td>0.64</td>\n",
       "      <td>625.0</td>\n",
       "      <td>Negotiation - 3x3 Conv Entropy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.780488</td>\n",
       "      <td>0.64</td>\n",
       "      <td>1.0</td>\n",
       "      <td>400.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>225.0</td>\n",
       "      <td>0.64</td>\n",
       "      <td>0.390244</td>\n",
       "      <td>0.32</td>\n",
       "      <td>0.5</td>\n",
       "      <td>625.0</td>\n",
       "      <td>0.499512</td>\n",
       "      <td>0.4096</td>\n",
       "      <td>0.64</td>\n",
       "      <td>625.0</td>\n",
       "      <td>Negotiation - 5x5 Conv Entropy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.780488</td>\n",
       "      <td>0.64</td>\n",
       "      <td>1.0</td>\n",
       "      <td>400.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>225.0</td>\n",
       "      <td>0.64</td>\n",
       "      <td>0.390244</td>\n",
       "      <td>0.32</td>\n",
       "      <td>0.5</td>\n",
       "      <td>625.0</td>\n",
       "      <td>0.499512</td>\n",
       "      <td>0.4096</td>\n",
       "      <td>0.64</td>\n",
       "      <td>625.0</td>\n",
       "      <td>Negotiation - Mean Entropy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.780488</td>\n",
       "      <td>0.64</td>\n",
       "      <td>1.0</td>\n",
       "      <td>400.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>225.0</td>\n",
       "      <td>0.64</td>\n",
       "      <td>0.390244</td>\n",
       "      <td>0.32</td>\n",
       "      <td>0.5</td>\n",
       "      <td>625.0</td>\n",
       "      <td>0.499512</td>\n",
       "      <td>0.4096</td>\n",
       "      <td>0.64</td>\n",
       "      <td>625.0</td>\n",
       "      <td>Negotiation - Pixelwise Entropy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.780488</td>\n",
       "      <td>0.64</td>\n",
       "      <td>1.0</td>\n",
       "      <td>400.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>225.0</td>\n",
       "      <td>0.64</td>\n",
       "      <td>0.390244</td>\n",
       "      <td>0.32</td>\n",
       "      <td>0.5</td>\n",
       "      <td>625.0</td>\n",
       "      <td>0.499512</td>\n",
       "      <td>0.4096</td>\n",
       "      <td>0.64</td>\n",
       "      <td>625.0</td>\n",
       "      <td>Weighted Mean - 3x3 Conv Entropy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.780488</td>\n",
       "      <td>0.64</td>\n",
       "      <td>1.0</td>\n",
       "      <td>400.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>225.0</td>\n",
       "      <td>0.64</td>\n",
       "      <td>0.390244</td>\n",
       "      <td>0.32</td>\n",
       "      <td>0.5</td>\n",
       "      <td>625.0</td>\n",
       "      <td>0.499512</td>\n",
       "      <td>0.4096</td>\n",
       "      <td>0.64</td>\n",
       "      <td>625.0</td>\n",
       "      <td>Weighted Mean - 5x5 Conv Entropy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.780488</td>\n",
       "      <td>0.64</td>\n",
       "      <td>1.0</td>\n",
       "      <td>400.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>225.0</td>\n",
       "      <td>0.64</td>\n",
       "      <td>0.390244</td>\n",
       "      <td>0.32</td>\n",
       "      <td>0.5</td>\n",
       "      <td>625.0</td>\n",
       "      <td>0.499512</td>\n",
       "      <td>0.4096</td>\n",
       "      <td>0.64</td>\n",
       "      <td>625.0</td>\n",
       "      <td>Weighted Mean - Mean Entropy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.780488</td>\n",
       "      <td>0.64</td>\n",
       "      <td>1.0</td>\n",
       "      <td>400.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>225.0</td>\n",
       "      <td>0.64</td>\n",
       "      <td>0.390244</td>\n",
       "      <td>0.32</td>\n",
       "      <td>0.5</td>\n",
       "      <td>625.0</td>\n",
       "      <td>0.499512</td>\n",
       "      <td>0.4096</td>\n",
       "      <td>0.64</td>\n",
       "      <td>625.0</td>\n",
       "      <td>Weighted Mean - Pixelwise Entropy</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Label 0_f1-score  Label 0_precision  Label 0_recall  Label 0_support  \\\n",
       "0           0.780488               0.64             1.0            400.0   \n",
       "1           0.780488               0.64             1.0            400.0   \n",
       "2           0.780488               0.64             1.0            400.0   \n",
       "3           0.780488               0.64             1.0            400.0   \n",
       "4           0.780488               0.64             1.0            400.0   \n",
       "5           0.780488               0.64             1.0            400.0   \n",
       "6           0.780488               0.64             1.0            400.0   \n",
       "7           0.780488               0.64             1.0            400.0   \n",
       "8           0.780488               0.64             1.0            400.0   \n",
       "9           0.780488               0.64             1.0            400.0   \n",
       "10          0.780488               0.64             1.0            400.0   \n",
       "\n",
       "    Label 1_f1-score  Label 1_precision  Label 1_recall  Label 1_support  \\\n",
       "0                0.0                0.0             0.0            225.0   \n",
       "1                0.0                0.0             0.0            225.0   \n",
       "2                0.0                0.0             0.0            225.0   \n",
       "3                0.0                0.0             0.0            225.0   \n",
       "4                0.0                0.0             0.0            225.0   \n",
       "5                0.0                0.0             0.0            225.0   \n",
       "6                0.0                0.0             0.0            225.0   \n",
       "7                0.0                0.0             0.0            225.0   \n",
       "8                0.0                0.0             0.0            225.0   \n",
       "9                0.0                0.0             0.0            225.0   \n",
       "10               0.0                0.0             0.0            225.0   \n",
       "\n",
       "    accuracy  macro avg_f1-score  macro avg_precision  macro avg_recall  \\\n",
       "0       0.64            0.390244                 0.32               0.5   \n",
       "1       0.64            0.390244                 0.32               0.5   \n",
       "2       0.64            0.390244                 0.32               0.5   \n",
       "3       0.64            0.390244                 0.32               0.5   \n",
       "4       0.64            0.390244                 0.32               0.5   \n",
       "5       0.64            0.390244                 0.32               0.5   \n",
       "6       0.64            0.390244                 0.32               0.5   \n",
       "7       0.64            0.390244                 0.32               0.5   \n",
       "8       0.64            0.390244                 0.32               0.5   \n",
       "9       0.64            0.390244                 0.32               0.5   \n",
       "10      0.64            0.390244                 0.32               0.5   \n",
       "\n",
       "    macro avg_support  weighted avg_f1-score  weighted avg_precision  \\\n",
       "0               625.0               0.499512                  0.4096   \n",
       "1               625.0               0.499512                  0.4096   \n",
       "2               625.0               0.499512                  0.4096   \n",
       "3               625.0               0.499512                  0.4096   \n",
       "4               625.0               0.499512                  0.4096   \n",
       "5               625.0               0.499512                  0.4096   \n",
       "6               625.0               0.499512                  0.4096   \n",
       "7               625.0               0.499512                  0.4096   \n",
       "8               625.0               0.499512                  0.4096   \n",
       "9               625.0               0.499512                  0.4096   \n",
       "10              625.0               0.499512                  0.4096   \n",
       "\n",
       "    weighted avg_recall  weighted avg_support  \\\n",
       "0                  0.64                 625.0   \n",
       "1                  0.64                 625.0   \n",
       "2                  0.64                 625.0   \n",
       "3                  0.64                 625.0   \n",
       "4                  0.64                 625.0   \n",
       "5                  0.64                 625.0   \n",
       "6                  0.64                 625.0   \n",
       "7                  0.64                 625.0   \n",
       "8                  0.64                 625.0   \n",
       "9                  0.64                 625.0   \n",
       "10                 0.64                 625.0   \n",
       "\n",
       "                               method  \n",
       "0                     Majority Voting  \n",
       "1                    Maximum Proposal  \n",
       "2                       Mean Proposal  \n",
       "3      Negotiation - 3x3 Conv Entropy  \n",
       "4      Negotiation - 5x5 Conv Entropy  \n",
       "5          Negotiation - Mean Entropy  \n",
       "6     Negotiation - Pixelwise Entropy  \n",
       "7    Weighted Mean - 3x3 Conv Entropy  \n",
       "8    Weighted Mean - 5x5 Conv Entropy  \n",
       "9        Weighted Mean - Mean Entropy  \n",
       "10  Weighted Mean - Pixelwise Entropy  "
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "exp.run_experiment_on_list([predictions], [gt])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Unbalanced on C2 (Binary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_LABELS = 2\n",
    "N_AGENTS = 3\n",
    "\n",
    "mu_1 = 0.4\n",
    "mu_2 = 0.6\n",
    "std = 0.01\n",
    "c_star = 0\n",
    "template = templates['blob']\n",
    "\n",
    "# Generating agents\n",
    "agents = [agent_binary_unbalanced(mu_1=mu_1, mu_2=mu_2, std=std) for a in range(N_AGENTS)]\n",
    "# Generating ground truth and predictions\n",
    "gt = generate_ground_truth(template, N_LABELS)\n",
    "predictions = np.stack([generate_predictions(template, agent_matrix) for agent_matrix in agents])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample 0 Consensus Reached at step, current step: 0\n",
      "Sample 0 Consensus Reached at step, current step: 0\n",
      "Sample 0 Consensus Reached at step, current step: 0\n",
      "Sample 0 Consensus Reached at step, current step: 0\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Label 0_f1-score</th>\n",
       "      <th>Label 0_precision</th>\n",
       "      <th>Label 0_recall</th>\n",
       "      <th>Label 0_support</th>\n",
       "      <th>Label 1_f1-score</th>\n",
       "      <th>Label 1_precision</th>\n",
       "      <th>Label 1_recall</th>\n",
       "      <th>Label 1_support</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>macro avg_f1-score</th>\n",
       "      <th>macro avg_precision</th>\n",
       "      <th>macro avg_recall</th>\n",
       "      <th>macro avg_support</th>\n",
       "      <th>weighted avg_f1-score</th>\n",
       "      <th>weighted avg_precision</th>\n",
       "      <th>weighted avg_recall</th>\n",
       "      <th>weighted avg_support</th>\n",
       "      <th>method</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>400.0</td>\n",
       "      <td>0.529412</td>\n",
       "      <td>0.36</td>\n",
       "      <td>1.0</td>\n",
       "      <td>225.0</td>\n",
       "      <td>0.36</td>\n",
       "      <td>0.264706</td>\n",
       "      <td>0.18</td>\n",
       "      <td>0.5</td>\n",
       "      <td>625.0</td>\n",
       "      <td>0.190588</td>\n",
       "      <td>0.1296</td>\n",
       "      <td>0.36</td>\n",
       "      <td>625.0</td>\n",
       "      <td>Majority Voting</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>400.0</td>\n",
       "      <td>0.529412</td>\n",
       "      <td>0.36</td>\n",
       "      <td>1.0</td>\n",
       "      <td>225.0</td>\n",
       "      <td>0.36</td>\n",
       "      <td>0.264706</td>\n",
       "      <td>0.18</td>\n",
       "      <td>0.5</td>\n",
       "      <td>625.0</td>\n",
       "      <td>0.190588</td>\n",
       "      <td>0.1296</td>\n",
       "      <td>0.36</td>\n",
       "      <td>625.0</td>\n",
       "      <td>Maximum Proposal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>400.0</td>\n",
       "      <td>0.529412</td>\n",
       "      <td>0.36</td>\n",
       "      <td>1.0</td>\n",
       "      <td>225.0</td>\n",
       "      <td>0.36</td>\n",
       "      <td>0.264706</td>\n",
       "      <td>0.18</td>\n",
       "      <td>0.5</td>\n",
       "      <td>625.0</td>\n",
       "      <td>0.190588</td>\n",
       "      <td>0.1296</td>\n",
       "      <td>0.36</td>\n",
       "      <td>625.0</td>\n",
       "      <td>Mean Proposal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>400.0</td>\n",
       "      <td>0.529412</td>\n",
       "      <td>0.36</td>\n",
       "      <td>1.0</td>\n",
       "      <td>225.0</td>\n",
       "      <td>0.36</td>\n",
       "      <td>0.264706</td>\n",
       "      <td>0.18</td>\n",
       "      <td>0.5</td>\n",
       "      <td>625.0</td>\n",
       "      <td>0.190588</td>\n",
       "      <td>0.1296</td>\n",
       "      <td>0.36</td>\n",
       "      <td>625.0</td>\n",
       "      <td>Negotiation - 3x3 Conv Entropy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>400.0</td>\n",
       "      <td>0.529412</td>\n",
       "      <td>0.36</td>\n",
       "      <td>1.0</td>\n",
       "      <td>225.0</td>\n",
       "      <td>0.36</td>\n",
       "      <td>0.264706</td>\n",
       "      <td>0.18</td>\n",
       "      <td>0.5</td>\n",
       "      <td>625.0</td>\n",
       "      <td>0.190588</td>\n",
       "      <td>0.1296</td>\n",
       "      <td>0.36</td>\n",
       "      <td>625.0</td>\n",
       "      <td>Negotiation - 5x5 Conv Entropy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>400.0</td>\n",
       "      <td>0.529412</td>\n",
       "      <td>0.36</td>\n",
       "      <td>1.0</td>\n",
       "      <td>225.0</td>\n",
       "      <td>0.36</td>\n",
       "      <td>0.264706</td>\n",
       "      <td>0.18</td>\n",
       "      <td>0.5</td>\n",
       "      <td>625.0</td>\n",
       "      <td>0.190588</td>\n",
       "      <td>0.1296</td>\n",
       "      <td>0.36</td>\n",
       "      <td>625.0</td>\n",
       "      <td>Negotiation - Mean Entropy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>400.0</td>\n",
       "      <td>0.529412</td>\n",
       "      <td>0.36</td>\n",
       "      <td>1.0</td>\n",
       "      <td>225.0</td>\n",
       "      <td>0.36</td>\n",
       "      <td>0.264706</td>\n",
       "      <td>0.18</td>\n",
       "      <td>0.5</td>\n",
       "      <td>625.0</td>\n",
       "      <td>0.190588</td>\n",
       "      <td>0.1296</td>\n",
       "      <td>0.36</td>\n",
       "      <td>625.0</td>\n",
       "      <td>Negotiation - Pixelwise Entropy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>400.0</td>\n",
       "      <td>0.529412</td>\n",
       "      <td>0.36</td>\n",
       "      <td>1.0</td>\n",
       "      <td>225.0</td>\n",
       "      <td>0.36</td>\n",
       "      <td>0.264706</td>\n",
       "      <td>0.18</td>\n",
       "      <td>0.5</td>\n",
       "      <td>625.0</td>\n",
       "      <td>0.190588</td>\n",
       "      <td>0.1296</td>\n",
       "      <td>0.36</td>\n",
       "      <td>625.0</td>\n",
       "      <td>Weighted Mean - 3x3 Conv Entropy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>400.0</td>\n",
       "      <td>0.529412</td>\n",
       "      <td>0.36</td>\n",
       "      <td>1.0</td>\n",
       "      <td>225.0</td>\n",
       "      <td>0.36</td>\n",
       "      <td>0.264706</td>\n",
       "      <td>0.18</td>\n",
       "      <td>0.5</td>\n",
       "      <td>625.0</td>\n",
       "      <td>0.190588</td>\n",
       "      <td>0.1296</td>\n",
       "      <td>0.36</td>\n",
       "      <td>625.0</td>\n",
       "      <td>Weighted Mean - 5x5 Conv Entropy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>400.0</td>\n",
       "      <td>0.529412</td>\n",
       "      <td>0.36</td>\n",
       "      <td>1.0</td>\n",
       "      <td>225.0</td>\n",
       "      <td>0.36</td>\n",
       "      <td>0.264706</td>\n",
       "      <td>0.18</td>\n",
       "      <td>0.5</td>\n",
       "      <td>625.0</td>\n",
       "      <td>0.190588</td>\n",
       "      <td>0.1296</td>\n",
       "      <td>0.36</td>\n",
       "      <td>625.0</td>\n",
       "      <td>Weighted Mean - Mean Entropy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>400.0</td>\n",
       "      <td>0.529412</td>\n",
       "      <td>0.36</td>\n",
       "      <td>1.0</td>\n",
       "      <td>225.0</td>\n",
       "      <td>0.36</td>\n",
       "      <td>0.264706</td>\n",
       "      <td>0.18</td>\n",
       "      <td>0.5</td>\n",
       "      <td>625.0</td>\n",
       "      <td>0.190588</td>\n",
       "      <td>0.1296</td>\n",
       "      <td>0.36</td>\n",
       "      <td>625.0</td>\n",
       "      <td>Weighted Mean - Pixelwise Entropy</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Label 0_f1-score  Label 0_precision  Label 0_recall  Label 0_support  \\\n",
       "0                0.0                0.0             0.0            400.0   \n",
       "1                0.0                0.0             0.0            400.0   \n",
       "2                0.0                0.0             0.0            400.0   \n",
       "3                0.0                0.0             0.0            400.0   \n",
       "4                0.0                0.0             0.0            400.0   \n",
       "5                0.0                0.0             0.0            400.0   \n",
       "6                0.0                0.0             0.0            400.0   \n",
       "7                0.0                0.0             0.0            400.0   \n",
       "8                0.0                0.0             0.0            400.0   \n",
       "9                0.0                0.0             0.0            400.0   \n",
       "10               0.0                0.0             0.0            400.0   \n",
       "\n",
       "    Label 1_f1-score  Label 1_precision  Label 1_recall  Label 1_support  \\\n",
       "0           0.529412               0.36             1.0            225.0   \n",
       "1           0.529412               0.36             1.0            225.0   \n",
       "2           0.529412               0.36             1.0            225.0   \n",
       "3           0.529412               0.36             1.0            225.0   \n",
       "4           0.529412               0.36             1.0            225.0   \n",
       "5           0.529412               0.36             1.0            225.0   \n",
       "6           0.529412               0.36             1.0            225.0   \n",
       "7           0.529412               0.36             1.0            225.0   \n",
       "8           0.529412               0.36             1.0            225.0   \n",
       "9           0.529412               0.36             1.0            225.0   \n",
       "10          0.529412               0.36             1.0            225.0   \n",
       "\n",
       "    accuracy  macro avg_f1-score  macro avg_precision  macro avg_recall  \\\n",
       "0       0.36            0.264706                 0.18               0.5   \n",
       "1       0.36            0.264706                 0.18               0.5   \n",
       "2       0.36            0.264706                 0.18               0.5   \n",
       "3       0.36            0.264706                 0.18               0.5   \n",
       "4       0.36            0.264706                 0.18               0.5   \n",
       "5       0.36            0.264706                 0.18               0.5   \n",
       "6       0.36            0.264706                 0.18               0.5   \n",
       "7       0.36            0.264706                 0.18               0.5   \n",
       "8       0.36            0.264706                 0.18               0.5   \n",
       "9       0.36            0.264706                 0.18               0.5   \n",
       "10      0.36            0.264706                 0.18               0.5   \n",
       "\n",
       "    macro avg_support  weighted avg_f1-score  weighted avg_precision  \\\n",
       "0               625.0               0.190588                  0.1296   \n",
       "1               625.0               0.190588                  0.1296   \n",
       "2               625.0               0.190588                  0.1296   \n",
       "3               625.0               0.190588                  0.1296   \n",
       "4               625.0               0.190588                  0.1296   \n",
       "5               625.0               0.190588                  0.1296   \n",
       "6               625.0               0.190588                  0.1296   \n",
       "7               625.0               0.190588                  0.1296   \n",
       "8               625.0               0.190588                  0.1296   \n",
       "9               625.0               0.190588                  0.1296   \n",
       "10              625.0               0.190588                  0.1296   \n",
       "\n",
       "    weighted avg_recall  weighted avg_support  \\\n",
       "0                  0.36                 625.0   \n",
       "1                  0.36                 625.0   \n",
       "2                  0.36                 625.0   \n",
       "3                  0.36                 625.0   \n",
       "4                  0.36                 625.0   \n",
       "5                  0.36                 625.0   \n",
       "6                  0.36                 625.0   \n",
       "7                  0.36                 625.0   \n",
       "8                  0.36                 625.0   \n",
       "9                  0.36                 625.0   \n",
       "10                 0.36                 625.0   \n",
       "\n",
       "                               method  \n",
       "0                     Majority Voting  \n",
       "1                    Maximum Proposal  \n",
       "2                       Mean Proposal  \n",
       "3      Negotiation - 3x3 Conv Entropy  \n",
       "4      Negotiation - 5x5 Conv Entropy  \n",
       "5          Negotiation - Mean Entropy  \n",
       "6     Negotiation - Pixelwise Entropy  \n",
       "7    Weighted Mean - 3x3 Conv Entropy  \n",
       "8    Weighted Mean - 5x5 Conv Entropy  \n",
       "9        Weighted Mean - Mean Entropy  \n",
       "10  Weighted Mean - Pixelwise Entropy  "
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "exp.run_experiment_on_list([predictions], [gt])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Expert C* (Multiclass)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_LABELS = 5\n",
    "N_AGENTS = 3\n",
    "\n",
    "mu_star = 1.5/N_LABELS\n",
    "mu = 1/N_LABELS\n",
    "std = 0.01\n",
    "c_star = 0\n",
    "template = templates['blobs']\n",
    "\n",
    "# Generating agents\n",
    "agents = [agent_expert(mu_star=mu_star, mu=mu, std=std, c_star=c_star, n_labels=N_LABELS) for a in range(N_AGENTS)]\n",
    "# Generating ground truth and predictions\n",
    "gt = generate_ground_truth(template, N_LABELS)\n",
    "predictions = np.stack([generate_predictions(template, agent_matrix) for agent_matrix in agents])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3, 25, 25, 5)"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample 0 Consensus Reached at step, current step: 0\n",
      "Sample 0 Consensus Reached at step, current step: 0\n",
      "Sample 0 Consensus Reached at step, current step: 0\n",
      "Sample 0 Consensus Reached at step, current step: 0\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Label 0_f1-score</th>\n",
       "      <th>Label 0_precision</th>\n",
       "      <th>Label 0_recall</th>\n",
       "      <th>Label 0_support</th>\n",
       "      <th>Label 1_f1-score</th>\n",
       "      <th>Label 1_precision</th>\n",
       "      <th>Label 1_recall</th>\n",
       "      <th>Label 1_support</th>\n",
       "      <th>Label 2_f1-score</th>\n",
       "      <th>Label 2_precision</th>\n",
       "      <th>...</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>macro avg_f1-score</th>\n",
       "      <th>macro avg_precision</th>\n",
       "      <th>macro avg_recall</th>\n",
       "      <th>macro avg_support</th>\n",
       "      <th>weighted avg_f1-score</th>\n",
       "      <th>weighted avg_precision</th>\n",
       "      <th>weighted avg_recall</th>\n",
       "      <th>weighted avg_support</th>\n",
       "      <th>method</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>205.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.328</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.2</td>\n",
       "      <td>625.0</td>\n",
       "      <td>0.328</td>\n",
       "      <td>0.328</td>\n",
       "      <td>0.328</td>\n",
       "      <td>625.0</td>\n",
       "      <td>Majority Voting</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>205.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.328</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.2</td>\n",
       "      <td>625.0</td>\n",
       "      <td>0.328</td>\n",
       "      <td>0.328</td>\n",
       "      <td>0.328</td>\n",
       "      <td>625.0</td>\n",
       "      <td>Maximum Proposal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>205.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.328</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.2</td>\n",
       "      <td>625.0</td>\n",
       "      <td>0.328</td>\n",
       "      <td>0.328</td>\n",
       "      <td>0.328</td>\n",
       "      <td>625.0</td>\n",
       "      <td>Mean Proposal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>205.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.328</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.2</td>\n",
       "      <td>625.0</td>\n",
       "      <td>0.328</td>\n",
       "      <td>0.328</td>\n",
       "      <td>0.328</td>\n",
       "      <td>625.0</td>\n",
       "      <td>Negotiation - 3x3 Conv Entropy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>205.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.328</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.2</td>\n",
       "      <td>625.0</td>\n",
       "      <td>0.328</td>\n",
       "      <td>0.328</td>\n",
       "      <td>0.328</td>\n",
       "      <td>625.0</td>\n",
       "      <td>Negotiation - 5x5 Conv Entropy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>205.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.328</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.2</td>\n",
       "      <td>625.0</td>\n",
       "      <td>0.328</td>\n",
       "      <td>0.328</td>\n",
       "      <td>0.328</td>\n",
       "      <td>625.0</td>\n",
       "      <td>Negotiation - Mean Entropy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>205.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.328</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.2</td>\n",
       "      <td>625.0</td>\n",
       "      <td>0.328</td>\n",
       "      <td>0.328</td>\n",
       "      <td>0.328</td>\n",
       "      <td>625.0</td>\n",
       "      <td>Negotiation - Pixelwise Entropy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>205.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.328</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.2</td>\n",
       "      <td>625.0</td>\n",
       "      <td>0.328</td>\n",
       "      <td>0.328</td>\n",
       "      <td>0.328</td>\n",
       "      <td>625.0</td>\n",
       "      <td>Weighted Mean - 3x3 Conv Entropy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>205.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.328</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.2</td>\n",
       "      <td>625.0</td>\n",
       "      <td>0.328</td>\n",
       "      <td>0.328</td>\n",
       "      <td>0.328</td>\n",
       "      <td>625.0</td>\n",
       "      <td>Weighted Mean - 5x5 Conv Entropy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>205.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.328</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.2</td>\n",
       "      <td>625.0</td>\n",
       "      <td>0.328</td>\n",
       "      <td>0.328</td>\n",
       "      <td>0.328</td>\n",
       "      <td>625.0</td>\n",
       "      <td>Weighted Mean - Mean Entropy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>205.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.328</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.2</td>\n",
       "      <td>625.0</td>\n",
       "      <td>0.328</td>\n",
       "      <td>0.328</td>\n",
       "      <td>0.328</td>\n",
       "      <td>625.0</td>\n",
       "      <td>Weighted Mean - Pixelwise Entropy</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>11 rows  30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    Label 0_f1-score  Label 0_precision  Label 0_recall  Label 0_support  \\\n",
       "0                1.0                1.0             1.0            205.0   \n",
       "1                1.0                1.0             1.0            205.0   \n",
       "2                1.0                1.0             1.0            205.0   \n",
       "3                1.0                1.0             1.0            205.0   \n",
       "4                1.0                1.0             1.0            205.0   \n",
       "5                1.0                1.0             1.0            205.0   \n",
       "6                1.0                1.0             1.0            205.0   \n",
       "7                1.0                1.0             1.0            205.0   \n",
       "8                1.0                1.0             1.0            205.0   \n",
       "9                1.0                1.0             1.0            205.0   \n",
       "10               1.0                1.0             1.0            205.0   \n",
       "\n",
       "    Label 1_f1-score  Label 1_precision  Label 1_recall  Label 1_support  \\\n",
       "0                0.0                0.0             0.0            100.0   \n",
       "1                0.0                0.0             0.0            100.0   \n",
       "2                0.0                0.0             0.0            100.0   \n",
       "3                0.0                0.0             0.0            100.0   \n",
       "4                0.0                0.0             0.0            100.0   \n",
       "5                0.0                0.0             0.0            100.0   \n",
       "6                0.0                0.0             0.0            100.0   \n",
       "7                0.0                0.0             0.0            100.0   \n",
       "8                0.0                0.0             0.0            100.0   \n",
       "9                0.0                0.0             0.0            100.0   \n",
       "10               0.0                0.0             0.0            100.0   \n",
       "\n",
       "    Label 2_f1-score  Label 2_precision  ...  accuracy  macro avg_f1-score  \\\n",
       "0                0.0                0.0  ...     0.328                 0.2   \n",
       "1                0.0                0.0  ...     0.328                 0.2   \n",
       "2                0.0                0.0  ...     0.328                 0.2   \n",
       "3                0.0                0.0  ...     0.328                 0.2   \n",
       "4                0.0                0.0  ...     0.328                 0.2   \n",
       "5                0.0                0.0  ...     0.328                 0.2   \n",
       "6                0.0                0.0  ...     0.328                 0.2   \n",
       "7                0.0                0.0  ...     0.328                 0.2   \n",
       "8                0.0                0.0  ...     0.328                 0.2   \n",
       "9                0.0                0.0  ...     0.328                 0.2   \n",
       "10               0.0                0.0  ...     0.328                 0.2   \n",
       "\n",
       "    macro avg_precision  macro avg_recall  macro avg_support  \\\n",
       "0                   0.2               0.2              625.0   \n",
       "1                   0.2               0.2              625.0   \n",
       "2                   0.2               0.2              625.0   \n",
       "3                   0.2               0.2              625.0   \n",
       "4                   0.2               0.2              625.0   \n",
       "5                   0.2               0.2              625.0   \n",
       "6                   0.2               0.2              625.0   \n",
       "7                   0.2               0.2              625.0   \n",
       "8                   0.2               0.2              625.0   \n",
       "9                   0.2               0.2              625.0   \n",
       "10                  0.2               0.2              625.0   \n",
       "\n",
       "    weighted avg_f1-score  weighted avg_precision  weighted avg_recall  \\\n",
       "0                   0.328                   0.328                0.328   \n",
       "1                   0.328                   0.328                0.328   \n",
       "2                   0.328                   0.328                0.328   \n",
       "3                   0.328                   0.328                0.328   \n",
       "4                   0.328                   0.328                0.328   \n",
       "5                   0.328                   0.328                0.328   \n",
       "6                   0.328                   0.328                0.328   \n",
       "7                   0.328                   0.328                0.328   \n",
       "8                   0.328                   0.328                0.328   \n",
       "9                   0.328                   0.328                0.328   \n",
       "10                  0.328                   0.328                0.328   \n",
       "\n",
       "    weighted avg_support                             method  \n",
       "0                  625.0                    Majority Voting  \n",
       "1                  625.0                   Maximum Proposal  \n",
       "2                  625.0                      Mean Proposal  \n",
       "3                  625.0     Negotiation - 3x3 Conv Entropy  \n",
       "4                  625.0     Negotiation - 5x5 Conv Entropy  \n",
       "5                  625.0         Negotiation - Mean Entropy  \n",
       "6                  625.0    Negotiation - Pixelwise Entropy  \n",
       "7                  625.0   Weighted Mean - 3x3 Conv Entropy  \n",
       "8                  625.0   Weighted Mean - 5x5 Conv Entropy  \n",
       "9                  625.0       Weighted Mean - Mean Entropy  \n",
       "10                 625.0  Weighted Mean - Pixelwise Entropy  \n",
       "\n",
       "[11 rows x 30 columns]"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "exp.run_experiment_on_list([predictions], [gt])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Add unbalanced multiclass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experimental Design (Binary)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1 balanced agent vs 2, 4, 8 unbalanced on C1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "c_star = 0\n",
    "template = templates['blob']\n",
    "N_LABELS = 2\n",
    "gt = generate_ground_truth(template, N_LABELS)\n",
    "SAMPLES = 30\n",
    "log = pd.DataFrame()\n",
    "for unb_agents in [2, 4, 8]:\n",
    "    for std in [0.01,0.05,0.1,0.2]:\n",
    "        for mu_balanced in [.6, .75, .9]:\n",
    "            # Balanced Agent\n",
    "            balanced = agent_binary_balanced(mu=mu, std=std)\n",
    "\n",
    "            for mu_1_unbalanced in [.6, .75, .9]:\n",
    "                for mu_2_unbalanced in [0.4, 0.5]:\n",
    "                    # Running \"SAMPLES\" times\n",
    "                    prediction_runs = list()\n",
    "\n",
    "                    for i in range(SAMPLES):\n",
    "                        agents = [balanced] + [agent_binary_unbalanced(mu_1=mu_1_unbalanced, mu_2=mu_2_unbalanced, std=std) for a in range(unb_agents)]        \n",
    "                        predictions = np.stack([generate_predictions(template, agent_matrix) for agent_matrix in agents])\n",
    "                        prediction_runs.append(predictions)\n",
    "\n",
    "                    results = exp.run_experiment_on_list(prediction_runs, [gt]*SAMPLES)\n",
    "                    results['unbalanced_agents'] = unb_agents\n",
    "                    results['mu_balanced'] = mu_balanced\n",
    "                    results['mu_1_unbalanced'] = mu_1_unbalanced\n",
    "                    results['mu_2_unbalanced'] = mu_2_unbalanced\n",
    "                    results['std'] = std\n",
    "                    log = log.append(results, ignore_index=True)\n",
    "log.to_csv('results/binary_balanced_vs_unbalanced_c1_std_{}'.format(std))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
