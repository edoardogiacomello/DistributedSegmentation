{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Installing TF2.0-preview\n",
    "Training model training is intended to run only on TF2.0+, If you are running a docker container with a previous version, please duplicate the container in order to preserve the old version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install tf-nightly-gpu-2.0-preview\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow.keras as tk\n",
    "import numpy as np\n",
    "import skimage.io as io\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.applications.mobilenet_v2 import preprocess_input\n",
    "import pandas as pd\n",
    "tf.test.is_gpu_available()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.0.0-alpha0'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Note on COCO_Animals\n",
    "The train/validation/test data comes from the COCO train2017 dataset, which is contained in /datasets/coco_animals/train. The validation folder containes unused data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Declaring environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "BASE_MODEL_PATH = 'models/model_base.h5'\n",
    "MODEL_OUT_FOLDER = 'models/'\n",
    "ID_TO_LABEL = {16: 'bird', 17: 'cat', 18: 'dog', 19: 'horse'}\n",
    "LABEL_TO_ID = {'bird': 16, 'cat': 17, 'dog': 18, 'horse': 19}\n",
    "CHANNEL_ORDER = [0, 16, 17, 18, 19] # Order of channels in output segmentation and corresponding dataset labels\n",
    "CHANNEL_NAMES = [ID_TO_LABEL[i] if i!=0 else 'other' for i in CHANNEL_ORDER]\n",
    "ALL_LABELS = list(LABEL_TO_ID.keys())\n",
    "ds_csv_paths = {dset: {label: 'datasets/coco_animals_{}_{}.csv'.format(dset, label) for label in ALL_LABELS} for dset in ['train', 'validation', 'test']}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_dataset(path, size=224, batch_size=32, filter_expr=None):\n",
    "    def parse_sample(png_path, seg_path, lab_name, lab_value):\n",
    "        resize = tf.image.resize_image_with_pad if tf.__version__.startswith('1.') else tf.image.resize_with_pad\n",
    "        png_raw = tf.io.read_file(png_path)\n",
    "        png = tf.image.decode_png(png_raw, channels=3)\n",
    "        png = resize(png, size, size)\n",
    "        png = preprocess_input(tf.cast(png, tf.float32))\n",
    "        seg_raw = tf.io.read_file(seg_path)\n",
    "        seg = tf.image.decode_png(seg_raw, channels=1)\n",
    "        seg = resize(seg, size, size, method=tf.image.ResizeMethod.NEAREST_NEIGHBOR)\n",
    "        segs = []\n",
    "        for lid in CHANNEL_ORDER:\n",
    "            # Creating 5 masks out of the index labels\n",
    "            segs.append(tf.cast(tf.equal(seg, lid), tf.float32))\n",
    "        seg = tf.concat(segs, axis=-1)\n",
    "        return png, seg\n",
    "    dataset = tf.data.experimental.CsvDataset(path, [tf.string, tf.string, tf.string, tf.int32], header=True)\n",
    "    if filter_expr:\n",
    "        dataset = dataset.filter(filter_expr)\n",
    "    dataset = dataset.shuffle(1000)\n",
    "    dataset = dataset.map(parse_sample)\n",
    "    dataset = dataset.batch(batch_size)\n",
    "    dataset = dataset.prefetch(1)\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_one_sample(dataset_label):\n",
    "    for png, seg in load_dataset(ds_csv_paths['train'][dataset_label]):\n",
    "        png = png.numpy()[0,...]\n",
    "        seg = seg.numpy()[0,...]\n",
    "        break\n",
    "    plt.figure(figsize=(18, 6))\n",
    "    plt.subplot(1, seg.shape[-1]+1, 1)\n",
    "    plt.axis('off')\n",
    "    io.imshow(png)\n",
    "    for i in range(seg.shape[-1]):\n",
    "        plt.subplot(1, seg.shape[-1]+1, i+2)\n",
    "        plt.axis('off')\n",
    "        io.imshow(seg[...,i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(label, input_model=BASE_MODEL_PATH, output_folder=MODEL_OUT_FOLDER, ):\n",
    "    \n",
    "    # Load model\n",
    "    \n",
    "    \n",
    "    \n",
    "    # Train the model\n",
    "    return \n",
    "    \n",
    "\n",
    "    \n",
    "\n",
    "def predict(model, dataset_label):\n",
    "    for png, seg in load_dataset(ds_csv_paths['validation'][dataset_label], batch_size=1):\n",
    "        out = model.predict(png)[0,...]\n",
    "        png = png.numpy()[0,...]\n",
    "        seg = seg.numpy()[0,...]\n",
    "        \n",
    "        \n",
    "        plt.figure(figsize=(18, 6))\n",
    "        plt.subplot(2, seg.shape[-1]+1, 1)\n",
    "        plt.axis('off')\n",
    "        io.imshow(png)\n",
    "        for i in range(seg.shape[-1]):\n",
    "            plt.subplot(2, seg.shape[-1]+1, i+2)\n",
    "            plt.axis('off')\n",
    "            plt.title(CHANNEL_NAMES[i])\n",
    "            io.imshow(seg[...,i])\n",
    "        for i in range(out.shape[-1]):\n",
    "            plt.subplot(2, out.shape[-1]+1, seg.shape[-1]+1+i+2)\n",
    "            plt.axis('off')\n",
    "            plt.title(CHANNEL_NAMES[i])\n",
    "            io.imshow(out[...,i])\n",
    "        yield plt\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train the models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for target_label in ['dog', 'bird', 'horse', 'cat']:\n",
    "    history = train_model(target_label, epochs=2)\n",
    "    hist = pd.DataFrame(history.history)\n",
    "    hist.to_csv('models/history_{}.csv'.format(target_label))\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate models\n",
    "Models are evaluated separately for their target label and the others"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0625 13:23:56.392818 140413771372288 hdf5_format.py:224] No training configuration found in save file: the model was *not* compiled. Compile it manually.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      8/Unknown - 3s 327ms/step - loss: 0.3315 - accuracy: 0.0000e+00 - binary_accuracy: 0.7999 - false_positives_19: 6725.0000 - false_negatives_19: 12794554.0000 - precision_19: 0.0462 - recall_19: 2.5479e-05"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0625 13:24:09.264626 140413771372288 hdf5_format.py:224] No training configuration found in save file: the model was *not* compiled. Compile it manually.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      8/Unknown - 2s 301ms/step - loss: 0.3300 - accuracy: 0.0000e+00 - binary_accuracy: 0.7999 - false_positives_20: 7352.0000 - false_negatives_20: 11339397.0000 - precision_20: 0.0490 - recall_20: 3.3422e-05"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0625 13:24:20.741027 140413771372288 hdf5_format.py:224] No training configuration found in save file: the model was *not* compiled. Compile it manually.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      8/Unknown - 2s 292ms/step - loss: 0.3323 - accuracy: 0.0000e+00 - binary_accuracy: 0.7999 - false_positives_21: 6303.0000 - false_negatives_21: 11339734.0000 - precision_21: 0.0066 - recall_21: 3.7038e-06"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0625 13:24:32.311767 140413771372288 hdf5_format.py:224] No training configuration found in save file: the model was *not* compiled. Compile it manually.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      8/Unknown - 3s 326ms/step - loss: 0.3312 - accuracy: 0.0000e+00 - binary_accuracy: 0.7999 - false_positives_22: 6289.0000 - false_negatives_22: 12844764.0000 - precision_22: 0.0444 - recall_22: 2.2732e-05"
     ]
    }
   ],
   "source": [
    "base_metrics = {lab: evaluate('models/model_base.h5', lab) for lab in ['bird', 'cat', 'dog', 'horse']}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      8/Unknown - 3s 366ms/step - loss: 0.0209 - accuracy: 0.5440 - binary_accuracy: 0.9783 - false_positives_1: 615126.0000 - false_negatives_1: 615191.0000 - precision_1: 0.9458 - recall_1: 0.9457"
     ]
    },
    {
     "data": {
      "text/plain": [
       "([0.014624733167390028,\n",
       "  0.5413325,\n",
       "  0.98538685,\n",
       "  522381.0,\n",
       "  522471.0,\n",
       "  0.96347004,\n",
       "  0.96346396],\n",
       " [0.02085717290174216,\n",
       "  0.5439969,\n",
       "  0.97830087,\n",
       "  615126.0,\n",
       "  615191.0,\n",
       "  0.9457547,\n",
       "  0.9457493])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate('models/model_cat-500-0.98.h5', 'cat')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      8/Unknown - 3s 330ms/step - loss: 0.0274 - accuracy: 0.5105 - binary_accuracy: 0.9699 - false_positives: 854592.0000 - false_negatives: 854598.0000 - precision: 0.9246 - recall: 0.9246"
     ]
    },
    {
     "data": {
      "text/plain": [
       "([0.012869831485052904,\n",
       "  0.5234587,\n",
       "  0.98713106,\n",
       "  463300.0,\n",
       "  463302.0,\n",
       "  0.9678275,\n",
       "  0.9678274],\n",
       " [0.027432613307610154,\n",
       "  0.5105202,\n",
       "  0.96985495,\n",
       "  854592.0,\n",
       "  854598.0,\n",
       "  0.9246376,\n",
       "  0.92463714])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate('models/model_dog-500-0.98.h5', 'dog')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      8/Unknown - 4s 439ms/step - loss: 0.0159 - accuracy: 0.6226 - binary_accuracy: 0.9841 - false_positives_1: 507788.0000 - false_negatives_1: 507823.0000 - precision_1: 0.9603 - recall_1: 0.9603"
     ]
    },
    {
     "data": {
      "text/plain": [
       "([0.010003979583936078,\n",
       "  0.6380507,\n",
       "  0.9899777,\n",
       "  250178.0,\n",
       "  250185.0,\n",
       "  0.97494465,\n",
       "  0.974944],\n",
       " [0.01588962972164154,\n",
       "  0.62264305,\n",
       "  0.9841247,\n",
       "  507788.0,\n",
       "  507823.0,\n",
       "  0.9603131,\n",
       "  0.96031046])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate('models/model_bird-500-0.99.h5', 'bird')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      8/Unknown - 3s 381ms/step - loss: 0.0250 - accuracy: 0.5023 - binary_accuracy: 0.9750 - false_positives: 803281.0000 - false_negatives: 803285.0000 - precision: 0.9375 - recall: 0.9375"
     ]
    },
    {
     "data": {
      "text/plain": [
       "([0.016505081206560135,\n",
       "  0.488655,\n",
       "  0.98318064,\n",
       "  411413.0,\n",
       "  411414.0,\n",
       "  0.9579518,\n",
       "  0.9579517],\n",
       " [0.025014091515913606,\n",
       "  0.502264,\n",
       "  0.9749854,\n",
       "  803281.0,\n",
       "  803285.0,\n",
       "  0.93746376,\n",
       "  0.93746346])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate('models/model_horse-500-0.98.h5', 'horse')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
