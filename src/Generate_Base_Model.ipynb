{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow.keras as tk\n",
    "from tensorflow.keras.applications.mobilenet_v2 import preprocess_input\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import skimage.io as io\n",
    "import matplotlib.pyplot as plt\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SegmentationModel():\n",
    "    def __init__(self, label, size=224, threshold=0.5):\n",
    "        self.target_label = label\n",
    "        self.BASE_MODEL_PATH = 'models/model_base.h5'\n",
    "        self.MODEL_OUT_FOLDER = 'models/{}/'.format(label)\n",
    "        os.makedirs(self.MODEL_OUT_FOLDER, exist_ok=True)\n",
    "        self.ID_TO_LABEL = {16: 'bird', 17: 'cat', 18: 'dog', 19: 'horse'}\n",
    "        self.LABEL_TO_ID = {'bird': 16, 'cat': 17, 'dog': 18, 'horse': 19}\n",
    "        self.CHANNEL_ORDER = [0, 16, 17, 18, 19] # Order of channels in output segmentation and corresponding dataset labels\n",
    "        self.CHANNEL_NAMES = [self.ID_TO_LABEL[i] if i!=0 else 'other' for i in self.CHANNEL_ORDER]\n",
    "        self.ALL_LABELS = list(self.LABEL_TO_ID.keys())\n",
    "        self.ds_csv_paths = {dset: {label: 'datasets/coco_animals_{}_{}.csv'.format(dset, label) for label in self.ALL_LABELS} for dset in ['train', 'validation', 'test']}\n",
    "        self.n_labels = len(self.CHANNEL_ORDER)\n",
    "        self.size = size\n",
    "        self.threshold = threshold\n",
    "        \n",
    "    \n",
    "    def load_dataset(self, path, size=224, batch_size=32, filter_expr=None):\n",
    "        def parse_sample(png_path, seg_path, lab_name, lab_value):\n",
    "            resize = tf.image.resize_image_with_pad if tf.__version__.startswith('1.') else tf.image.resize_with_pad\n",
    "            png_raw = tf.io.read_file(png_path)\n",
    "            png = tf.image.decode_png(png_raw, channels=3)\n",
    "            png = resize(png, size, size)\n",
    "            png = preprocess_input(tf.cast(png, tf.float32))\n",
    "            seg_raw = tf.io.read_file(seg_path)\n",
    "            seg = tf.image.decode_png(seg_raw, channels=1)\n",
    "            seg = resize(seg, size, size, method=tf.image.ResizeMethod.NEAREST_NEIGHBOR)\n",
    "            segs = []\n",
    "            for lid in self.CHANNEL_ORDER:\n",
    "                # Creating 5 masks out of the index labels\n",
    "                segs.append(tf.cast(tf.equal(seg, lid), tf.float32))\n",
    "            seg = tf.concat(segs, axis=-1)\n",
    "            return png, seg\n",
    "        dataset = tf.data.experimental.CsvDataset(path, [tf.string, tf.string, tf.string, tf.int32], header=True)\n",
    "        if filter_expr:\n",
    "            dataset = dataset.filter(filter_expr)\n",
    "        dataset = dataset.shuffle(1000)\n",
    "        dataset = dataset.map(parse_sample)\n",
    "        dataset = dataset.batch(batch_size)\n",
    "        dataset = dataset.prefetch(1)\n",
    "        return dataset\n",
    "    \n",
    "    def load_base_network(self):\n",
    "        self.model = tk.models.load_model(self.BASE_MODEL_PATH)\n",
    "    \n",
    "    \n",
    "    def define_metric_accumulators(self):\n",
    "        self.train_loss = tf.metrics.Mean()\n",
    "        self.train_IoU = {label: tf.metrics.MeanIoU(num_classes=2) for label in self.ALL_LABELS}        \n",
    "        self.valid_loss = tf.metrics.Mean()\n",
    "        self.valid_IoU = {label: tf.metrics.MeanIoU(num_classes=2) for label in self.ALL_LABELS}\n",
    "\n",
    "    @tf.function\n",
    "    def train_step(self, x, y_true):\n",
    "        with tf.GradientTape() as tape:\n",
    "            y_pred = self.model(x,training=True)\n",
    "            loss = self.loss(y_true, y_pred)\n",
    "        gradients = tape.gradient(loss, self.model.trainable_variables)\n",
    "        self.optimizer.apply_gradients(zip(gradients, self.model.trainable_variables))\n",
    "        return loss\n",
    "    \n",
    "    @tf.function\n",
    "    def validation_step(self, x, y_true):\n",
    "        y_pred = self.model(x)\n",
    "        loss = self.loss(y_true, y_pred)\n",
    "        return loss\n",
    "\n",
    "    \n",
    "    def train(self, epochs=1000, batch_size=32, seed=123456780):\n",
    "        self.train_summary_writer = tf.summary.create_file_writer(self.MODEL_OUT_FOLDER+'train/')\n",
    "        self.valid_summary_writer = tf.summary.create_file_writer(self.MODEL_OUT_FOLDER+'validation/')\n",
    "        \n",
    "        tf.random.set_seed(seed)\n",
    "        \n",
    "        self.load_base_network()\n",
    "        self.define_metric_accumulators()\n",
    "        \n",
    "        self.loss = tk.losses.CategoricalCrossentropy()        \n",
    "        self.optimizer = tk.optimizers.Adam()\n",
    "        progbar = tk.utils.Progbar(None)\n",
    "        for e in range(epochs):\n",
    "            i = 0\n",
    "            # Train Step\n",
    "            for x, y in self.load_dataset(self.ds_csv_paths['train'][self.target_label], batch_size=batch_size, size=self.size):\n",
    "                train_step_loss = self.train_step(x, y)\n",
    "                self.train_loss.update_state(train_step_loss)\n",
    "                i += 1; progbar.update(i);\n",
    "            \n",
    "            i = 0\n",
    "            # Validation Step\n",
    "            for x, y in self.load_dataset(self.ds_csv_paths['validation'][self.target_label], batch_size=batch_size, size=self.size):\n",
    "                valid_step_loss = self.validation_step(x, y)\n",
    "                self.valid_loss.update_state(valid_step_loss)\n",
    "                i += 1; progbar.update(i);\n",
    "        \n",
    "            # Calculate train/validation metrics for each label separately\n",
    "            \n",
    "            for filter_label in self.ALL_LABELS:\n",
    "                # Filtering only data containing the target label\n",
    "                data_filter = lambda png, seg, label, label_id, target_lab=filter_label: tf.equal(label, self.target_label)\n",
    "                i = 0\n",
    "                for x, y_true in self.load_dataset(self.ds_csv_paths['train'][self.target_label], batch_size=batch_size, size=self.size, filter_expr=data_filter):\n",
    "                    y_pred = self.model(x)\n",
    "                    self.train_IoU[filter_label].update_state(y_true, tf.cast(y_pred > self.threshold, dtype=tf.float32), sample_weight=tf.tile(tf.one_hot(self.CHANNEL_NAMES.index(filter_label), depth=len(self.CHANNEL_NAMES))[tf.newaxis, tf.newaxis, tf.newaxis, ...], [y_pred.shape[0], self.size,self.size,1]))\n",
    "                    i += 1; progbar.update(i);\n",
    "                i = 0\n",
    "                for x, y_true in self.load_dataset(self.ds_csv_paths['validation'][self.target_label], batch_size=batch_size, size=self.size, filter_expr=data_filter):\n",
    "                    y_pred = self.model(x)\n",
    "                    self.valid_IoU[filter_label].update_state(y_true,  tf.cast(y_pred > self.threshold, dtype=tf.float32), sample_weight=tf.tile(tf.one_hot(self.CHANNEL_NAMES.index(filter_label), depth=len(self.CHANNEL_NAMES))[tf.newaxis, tf.newaxis, tf.newaxis, ...], [y_pred.shape[0], self.size,self.size,1]))\n",
    "                    i += 1; progbar.update(i);\n",
    "\n",
    "            # Visualization\n",
    "            with self.train_summary_writer.as_default():\n",
    "                tf.summary.scalar('loss', self.train_loss.result(), step=e)\n",
    "                self.train_loss.reset_states()\n",
    "                for l in self.train_IoU.keys():\n",
    "                    tf.summary.scalar('IOU_{}'.format(l), self.train_IoU[l].result(), step=e)\n",
    "                    self.train_IoU[l].reset_states()\n",
    "                    \n",
    "            with self.valid_summary_writer.as_default():\n",
    "                tf.summary.scalar('loss', self.valid_loss.result(), step=e)\n",
    "                self.valid_loss.reset_states()\n",
    "                for l in self.train_IoU.keys():\n",
    "                    tf.summary.scalar('IOU_{}'.format(l), self.valid_IoU[l].result(), step=e)\n",
    "                    self.valid_IoU[l].reset_states()\n",
    "            # Saving\n",
    "            tk.models.save_model(self.model, self.MODEL_OUT_FOLDER+'model_ep{}.h5'.format(e))\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = SegmentationModel('cat')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W0716 13:52:55.115557 139635017389824 hdf5_format.py:224] No training configuration found in save file: the model was *not* compiled. Compile it manually.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     16/Unknown - 55s 3s/step"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0716 13:53:51.245293 139635017389824 deprecation.py:323] From /usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/confusion_matrix.py:194: to_int64 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.cast` instead.\n",
      "W0716 13:53:51.249983 139635017389824 deprecation.py:323] From /usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/confusion_matrix.py:195: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.cast` instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      6/Unknown - 4366s 728s/step"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-8eea702cf98c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mnet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-2-67c1200bdbb0>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, epochs, batch_size, seed)\u001b[0m\n\u001b[1;32m    107\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_true\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_dataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mds_csv_paths\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'validation'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtarget_label\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilter_expr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdata_filter\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    108\u001b[0m                     \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 109\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalid_IoU\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mfilter_label\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate_state\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_pred\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mthreshold\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mone_hot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCHANNEL_NAMES\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilter_label\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdepth\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCHANNEL_NAMES\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnewaxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnewaxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnewaxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m...\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0my_pred\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    110\u001b[0m                     \u001b[0mi\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m;\u001b[0m \u001b[0mprogbar\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m;\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    111\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/gen_math_ops.py\u001b[0m in \u001b[0;36mgreater\u001b[0;34m(x, y, name)\u001b[0m\n\u001b[1;32m   4001\u001b[0m       _result = _pywrap_tensorflow.TFE_Py_FastPathExecute(\n\u001b[1;32m   4002\u001b[0m         \u001b[0m_ctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_context_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_ctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_thread_local_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"Greater\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4003\u001b[0;31m         name, _ctx._post_execution_callbacks, x, y)\n\u001b[0m\u001b[1;32m   4004\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0m_result\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4005\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0m_core\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_FallbackException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "net.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
